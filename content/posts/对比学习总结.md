---
title: "对比学习总结" 
date: 2024-04-25T12:44:51+08:00 #创建时间
lastmod: 2024-04-25T12:44:51+08:00 #更新时间
author: "张广益"
tags: ["对比学习", "Deep Learning"]
description: "简要介绍对比学习的一些思路和相关模型，并对其进行总结。"
draft: false # 是否为草稿
comments: false # 是否展示评论
showToc: true # 显示目录
TocOpen: true # 自动展开目录
TocSide: 'left'  # or 'right'
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
math: true
disableShare: false # 底部不显示分享栏
showbreadcrumbs: true # 顶部显示当前路径
---

# 对比学习总结[^1]

## 1.CV

### 百花齐放

#### **[InstDisc](https://arxiv.org/pdf/1805.01978.pdf)**

提出了**个体判别任务**和**memory bank**（字典形式）。正样本为自己，负样本为所有其他图片，负样本的特征存放在memory bank中。loss使用的是NCE loss。

![InstDisc](InstDisc.png)

skills: 由于memory bank里的特征数量通常较大，**Proximal Regularizatio**对memory bank里的特征进行动量更新，节省时间和内存。

[InvaSpread](https://arxiv.org/pdf/1904.03436.pdf)

基本的对比学习，相似的物体特征应该保持不变性，不相似的物体特征应该尽量分散开。选取了**个体判别任务**。正样本为自己经过数据增强后的图片，负样本为batch size里其他图片（包括原始图片和其数据增强后的图片），这样的好处在于，可以只用一个编码器去做端到端的训练。使用的loss为NCE loss的变体。

![InvaSpread](InvaSpread.png)

#### [CPC](https://arxiv.org/pdf/1807.03748.pdf)

选取了预测型的任务来做对比学习，对于模型的预测结果(z_t+1)来说，正样本为未来时刻的输入（x_t+1)通过编码器的输出，负样本为任意输入通过编码器的输出。

![CPC](CPC.png)

#### [CMC](https://arxiv.org/pdf/1906.05849.pdf)

多视角的对比学习，目的是增大所有视角之间的互信息，对于某个物体来说，正样本为其在其他视角（模态）下的信息，负样本为其他与物体

![CMC](CMC.png)

### CV双雄

#### [MoCov1](https://arxiv.org/pdf/1911.05722.pdf)

把之前对比学习的方法都归纳成一个字典查询的问题，思路和**[InstDisc](https://arxiv.org/pdf/1805.01978.pdf)**很类似。文章中提出了两个东西：**队列**和**动量编码器**，队列用来存储负样本的特征，动量编码器用来动态更新encoder，而不是动量的去更新负样本的特征。loss用的是info NCE loss。

![MoCov1](MoCov1.png)

创新点：**动量编码器**，后续对比学习的工作还在沿用这个skill。

#### [SimCLRv1](https://arxiv.org/pdf/2002.05709.pdf)

正负样本的构造方式与[InvaSpread](https://arxiv.org/pdf/1904.03436.pdf)相同，正样本为数据增强后的样本，负样本为batch里其他及其数据增强后的样本，simclr与InvaSpread的区别在于使用了更多的数据增强方式，在encoder后面增加了一个g函数(全连接层)，用了更大的batch size（4096）。

![SimCLRv1](SimCLRv1.png)

创新点：在编码器后面加了一个mlp层（projector），效果有了很大的提升。

#### [MoCov2](https://arxiv.org/pdf/2003.04297.pdf)

在原来的moco上面做了一些简单的改动，借鉴了simclr里面的一些技术，使用了更多的数据增强方式，以及在编码器后面加了一个mlp层，同时模型的训练epoch数也增加了（由200增加到800）。通常来说，无监督模型或者大型模型，训练越久模型效果越好。

![MoCov2](MoCov2.png)

#### [SimCLRv2](https://arxiv.org/pdf/2006.10029.pdf)

文章主要在讲大模型如何去做半监督学习。相比于simclr v1，论文的主要改动在于：换了一个更大的网络，实验了不同深度的mlp层(projection head)，使用了动量编码器。

![SimCLRv2](SimCLRv2.png)

[SWaV](https://arxiv.org/pdf/2006.09882.pdf)

将对比学习和聚类的方法融合在了一起，将样本去跟负样本的聚类中心做对比。基本流程是样本x通过数据增强得到$x_1, x_2$，再通过一个编码器$f(\theta)$得到两个特征$z_1,z_2$，接下来在与聚类中心c进行计算得到ground truth $Q_1,Q_2$，对$Q_1, Q_2$进行训练。

![SWaV](SWaV.png)

skill: Multi-crop

### 不用负样本

#### [BYOL](https://arxiv.org/pdf/2006.07733.pdf)

样本x通过两次不同的数据增强得到两个样本$v,v'$，再通过两个不同的编码器$f(\theta)$（结构一样，参数不一样）得到两个特征$y_{\theta},y_{\epsilon}$，然后再通过两个不同的mlp层得到$z_{\theta}, z'_{\epsilon}$，最终$z_{\theta}$通过一个全连接层$q_{\theta}$（网络结构与$g_{\theta}$相同）得到$q_{\theta}(z_{\theta})$，通过让$q_{\theta}(z_{\theta})$去学习$sg(z'_{\epsilon})$来完成训练。其中下面的编码器和projector采用的是动量更新（类似于MoCo）。loss使用的是mse loss

![BYOL](BYOL.png)



注：论文中使用的mlp层结构如下：

```python
import torch.nn as nn

def MLP(dim, projection_size, hidden_size=4096):
    return nn.Sequential(
        nn.Linear(dim, hidden_size),
        nn.BatchNorm1d(hidden_size),
        nn.ReLU(inplace=True),
        nn.Linear(hidden_size, projection_size)
    )

```

若去掉mlp层中的BatchNorm部分，模型效果会大大降低，原因在于去掉后会影像模型的初始化参数。

#### [SimSiam](https://arxiv.org/pdf/2011.10566.pdf)

思路跟BYOL类似，样本$x$通过两次数据增强得到$x_1, x_2$，$x_1$通过编码器f和一个projector得到h，通过h去学习$x_2$。由编码器f解码出来的特征来完成训练，其中stop-grad至关重要。

![SimSiam](SimSiam.png)

simsiam与其他模型的对比如下：

![simsiam与其他模型的对比](simsiam与其他模型的对比.png)

### Transformer

#### [MoCov3](https://arxiv.org/pdf/2104.02057.pdf)

模型网络结构融合了MoCo V2和SimSiam

![MoCov3](MoCov3.png)

trick：MoCo V3将编码器由原来的resnet换成了VIT，且在训练时将VIT 的patch projection层冻住（batchsize变大效果反而变差的问题在于patch projection层在训练时梯度过大）。

[DINO](https://arxiv.org/pdf/2104.14294.pdf)

思路和训练过程跟MoCo V3类似。

![DINO](DINO.png)

#### [CLIP](https://openai.com/blog/clip/)

将文本信息和图片信息相结合。训练时，配对的图片和描述文本为正样本，不配对的图片和文本描述为负样本，然后利用对比学习来训练。预测时，通过prompt来构造文本描述，然后计算每个选项的置信度。论文的创新点在于：1.对于分类或检测任务，训练时不用再指定类别，只要在训练数据中出现过的类别，模型都可以通过prompt的形式来预测出来；2.打通了文本和图像的限制，文本编码器和图像编码器都可以使用transformer结构，为后续多模态模型的发展提供了统一框架的可能。

![CLIP](CLIP.png)

## 2.NLP

#### [SimCSE](https://arxiv.org/pdf/2104.08821.pdf)

SimCSE论文中介绍了无监督和有监督两种训练方式。无监督训练时，作者将每个batch内的句子dropout两次，自己和自己为正样本，和batch内的其他句子为负样本，使用的loss为**NSE loss**：
$$
l_i = -\log \frac{e^{sim(h_i^{z_i}, h_i^{z_i'})/ \tau}}{\sum_{j=1}^N e^{sim(h_i^{z_i}, h_j^{z_j'})/ \tau}}
$$
其中$h_i^{z_i}, h_i^{z_i'}$为样本$h_i$经过两次dropout后的结果。

有监督训练时，对于样本对$(h_i, h_i^+, h_i^-)$，使用的loss如下：
$$
-\log \frac{e^{sim(h_i, h_i^+)/ \tau}}{\sum_{j=1}^N \bigg( e^{sim(h_i, h_j^+)/ \tau} + e^{sim(h_i, h_j^-)/ \tau} \bigg)}
$$
![SimCSE](SimCSE.png)

trick: 作者使用dropout作为数据增强的方式，实现时每个batch内放两次同一个句子即可，又简单又有效果，可谓大道至简了。

另外作者还提出了用Alignment（对齐性）和Uniformity（均匀性）来衡量一个模型的好坏，一个好的对比学习模型，应该是将相似的样本映射到尽可能聚拢的空间上，即具有对齐性；将不相似的样本映射到尽可能发散的空间上，即具有均匀性。

#### [ESimCSE](https://arxiv.org/pdf/2109.04380.pdf)[^2]

ESimCSE为SimCSE的增强版。SimCSE直接通过dropout两次来构造正样本，这样会导致正例对具有相同的长度，而负例对通常包含不同的长度信息，模型有可能会通过这一特征来区分正负样本。针对这一点，作者提出了**Word Repetition**的方法，即随机复制句子中的一些单词来使正例对的长度不同。另外作者还使用了动量编码器，动量编码器最早在MoCo中就有使用。

![EsimCSE](ESimCSE.png)

#### [ConSERT](https://arxiv.org/pdf/2105.11741.pdf)[^3]

作者也是在SimCSE的基础上进行了改进，主要改进点如下：

- 一个数据增强模块，作用于Embedding层，为同一个句子生成两个不同的增强版本（View）；
- 一个共享的BERT编码器，为输入的句子生成句向量。
- 一个对比损失层，用于在一个Batch的样本中计算对比损失，其思想是最大化同一个样本不同增强版本句向量的相似度，同时使得不同样本的句向量相互远离。

![ConSERT](ConSERT.png)

作者探索了不同的数据增强方式，包括**对抗攻击**，**打乱词序**，**裁剪**，**Dropout**，其中裁剪包括Token Cutoff(随机选取Token，将对应Token的Embedding整行置为零)和Feature Cutoff(随机选取Embedding的Feature，将选取的Feature维度整列置为零)。作者的结果显示打乱词序和Feature Cutoff的组合取得了最优性能。此外，就单种数据增强方法而言，打乱词序 > Token Cutoff >> Feature Cutoff ≈ Dropout >> None。

## 3.总结

![对比学习总结](对比学习总结.png)

## 参考资料

[^1]: 本文CV部分总结自李沐老师的[视频](https://www.bilibili.com/video/BV19S4y1M7hm?spm_id_from=333.999.0.0)和[github](https://github.com/mli/paper-reading#contrastive_learning)。
[^2]:[ESimCSE：无监督语义新SOTA，引入动量对比学习扩展负样本，效果远超SimCSE](https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247488529&idx=2&sn=fc55d54811d985b7824782ffeff364fd&scene=21#wechat_redirect)
[^3]:[ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%](https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html)
