<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>对抗训练简介</title>
    <link href="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/"/>
    <url>/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="对抗训练简介">对抗训练简介</h1><h2 id="发展背景">1.发展背景</h2><p>​ 对抗训练（Adversarial Training）最初由 GAN之父Ian Goodfellow</p><p>等人提出，作为一种防御对抗攻击的方法，最早应用在计算机视觉领域，用来解决利用对抗样本来恶意攻击模型的问题。</p><h2 id="基本思路">2.基本思路</h2><p>​ 我们定义<span class="math inline">\(D\)</span>为训练集，<span class="math inline">\(x\)</span>代表输入，<span class="math inline">\(y\)</span>代表标签，<span class="math inline">\(\theta\)</span>代表模型参数，<span class="math inline">\(L\)</span>为损失函数，<span class="math inline">\(r_{adv}\)</span>为扰动。对抗训练的思路就是在原始输入样本<span class="math inline">\(x\)</span>上增加一个扰动 <span class="math inline">\(r_{adv}\)</span>，得到<strong>对抗样本</strong>后，用其进行训练。我们可以把问题抽象成如下模型：<span class="math display">\[\min \limits_{\theta} -\log P(y|x+r_{adv};\theta)\]</span> 从模型优化的角度，我们可以将对抗训练拆解为两部分：</p><p>(1).从扰动的范围空间<span class="math inline">\(S\)</span>内找到对模型最有效的扰动，这部分可看作是对模型的攻击：<span class="math display">\[\max \limits_{r_{adv}\in S}L(\theta, x+r_{adv}, y)\]</span> (2).找到最鲁棒的模型参数<span class="math inline">\(\theta\)</span>使得对抗样本对模型的影响降到最低，也即模型的防御：<span class="math display">\[\min\limits_{\theta}E_{(x,y)\sim D}[\max\limits_{r_{adv}\in S}L(\theta,x+r_{adv}, y)]\]</span>上式就是对抗训练中最有名的Min-Max公式，它可以看成内部损失函数最大化+外部经验风险最小化的结合。</p><p>有了上述的分析，接下来的问题就在于：如何构造足够强的对抗样本？如何让模型具备最高的防御能力？</p><h3 id="对抗样本">对抗样本</h3><p>​ 在原论文中，作者提出了<strong>Fast Gradient SignMethod(FGSM)</strong>来构造输入样本的扰动。扰动的定义如下： <span class="math display">\[r_{adv} = \epsilon * sgn(\nabla_{x}L(\theta,x,y))\]</span> 其中<span class="math inline">\(sgn\)</span>为符号函数。</p><p><img src="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/adv_sample.png"></p><p>​ （熊猫加扰动后变成了长臂猿）</p><p>从FGSM的设计中我们也可以总结出对抗样本需要具备的两个特点：</p><p>​ 1.添加的扰动需要是微小的，对抗样本与原始样本之间需要满足约束<span class="math inline">\(\left\| x^* - x \right\|_{\infty} =\left\|r_{adv}\right\|_{\infty}\leq \epsilon\)</span>；</p><p>​ 2.应该从Loss梯度上升的方向来添加扰动，从而尽量使模型出错。</p><h2 id="主要方法">3.主要方法</h2><p>​上述提到的思路都是基于CV领域提出的，CV的输入是连续的RGB的值，根据上述方法算出扰动后可以直接加到输入上来构造对抗样本。对于NLP领域来说，有没有办法将这种思路迁移过来呢？答案肯定是有的。NLP的输入一般为one-hot向量，直接在上面加扰动肯定是不行的，Goodfellow在文章中</p><p>提出可以在连续的embedding上做扰动。这种方法相较于CV来说最大的不同是，CV的对抗样本可以还原成图像，但是NLP的对抗样本无法还原成某个单词或词组。<strong>所以在NLP任务中，对抗训练的目的不再是为了防御基于梯度的恶意攻击，更多是作为一种正则化手段来提高模型的泛化能力。</strong></p><p>NLP中常见的对抗训练有以下几种：</p><h3 id="fast-gradient-methodfgm">3.1 <a href="https://arxiv.org/pdf/1605.07725.pdf">Fast GradientMethod(FGM)</a></h3><p>​FGM在上文提到的FGSM上做了一点改动，将原本的符号函数变成了映射到单位球面上的向量：<span class="math display">\[g = \nabla_{x}L(\theta,x,y), \quad r_{adv} = \epsilon * g / \left\| g\right\|_2\]</span> 上式中<span class="math inline">\(x\)</span>为embedding向量，主要代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">对于每个x:</span><br><span class="hljs-string">  1.计算x的前向loss、反向传播得到梯度</span><br><span class="hljs-string">  2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r</span><br><span class="hljs-string">  3.计算x+r的前向loss，反向传播得到对抗的梯度，累加到(1)的梯度上</span><br><span class="hljs-string">  4.将embedding恢复为(1)时的值</span><br><span class="hljs-string">  5.根据(3)的梯度对参数进行更新</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FGM</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model</span>):<br>        self.model = model<br>        self.backup = &#123;&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">attack</span>(<span class="hljs-params">self, epsilon=<span class="hljs-number">1.</span>, emb_name=<span class="hljs-string">&#x27;emb.&#x27;</span></span>):<br>        <span class="hljs-comment"># 增加扰动</span><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name:<br>                self.backup[name] = param.data.clone()<br>                norm = torch.norm(param.grad)<br>                <span class="hljs-keyword">if</span> norm != <span class="hljs-number">0</span>:<br>                   <span class="hljs-comment"># 一个batch内的样本统一用一个范数归一化</span><br>                    r_at = epsilon * param.grad / norm<br>                    param.data.add_(r_at)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">restore</span>(<span class="hljs-params">self, emb_name=<span class="hljs-string">&#x27;emb.&#x27;</span></span>):<br>        <span class="hljs-comment"># 还原embedding向量</span><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name: <br>                <span class="hljs-keyword">assert</span> name <span class="hljs-keyword">in</span> self.backup<br>                param.data = self.backup[name]<br>        self.backup = &#123;&#125;<br></code></pre></td></tr></table></figure><blockquote><p>代码参考自：https://zhuanlan.zhihu.com/p/91269728</p></blockquote><p>原论文的代码中，是对一个batch内的每个样本分别求范数。</p><h3 id="projected-gradient-descentpgd">3.2 <a href="https://arxiv.org/pdf/1706.06083.pdf">Projected GradientDescent(PGD)</a></h3><p>​<strong>PGD</strong>从<strong>FGM</strong>的一步到位改成了做多次迭代，在寻找最优扰动时，作者采用了<strong>”小步走，多走几步“</strong>的迭代方法，每次走一小步，每次迭代都将扰动映射到约束空间内：<span class="math display">\[x_{t+1} = \mathop{\Pi} \limits_{r_{adv}\in S}(x_t + r_{adv})\]</span></p><p><span class="math display">\[r_{adv}=\alpha*g(x_t)/ \left\| g(x_t)\right\|_2,\quad g =\nabla_{x}L(\theta,x,y)\]</span></p><p>其中<span class="math inline">\(S=\left\{ r\in R^d: \left\|r\right\|_2 \leq \epsilon \right\}\)</span>为扰动的约束空间，<span class="math inline">\(\alpha\)</span>为每一步的步长，<span class="math inline">\(\mathop{\Pi} \limits_{r_{adv}\in S}(x_t +r_{adv})\)</span>表示将<span class="math inline">\((x_t +r_{adv})\)</span>映射到<span class="math inline">\(S\)</span>上。主要代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">对于每个x:</span><br><span class="hljs-string">  1.计算x的前向loss、反向传播得到梯度并备份</span><br><span class="hljs-string">  对于每步t:</span><br><span class="hljs-string">    2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r(超出范围则投影回S内)</span><br><span class="hljs-string">    3.t不是最后一步: 将梯度归0，根据1的x+r计算前后向并得到梯度</span><br><span class="hljs-string">    4.t是最后一步: 恢复(1)的梯度，计算最后的x+r并将梯度累加到(1)上</span><br><span class="hljs-string">  5.将embedding恢复为(1)时的值</span><br><span class="hljs-string">  6.根据(4)的梯度对参数进行更新</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PGD</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, steps</span>):<br>        self.model = model<br>        self.steps = steps<span class="hljs-comment"># 迭代步数</span><br>        self.emb_backup = &#123;&#125;<br>        self.grad_backup = &#123;&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">attack</span>(<span class="hljs-params">self, epsilon=<span class="hljs-number">1.</span>, alpha=<span class="hljs-number">0.3</span>, emb_name=<span class="hljs-string">&#x27;emb.&#x27;</span>, is_first_attack=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-comment"># emb_name为模型中embedding的参数名</span><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name:<br>                <span class="hljs-keyword">if</span> is_first_attack:<br>                    self.emb_backup[name] = param.data.clone()<br>                norm = torch.norm(param.grad)<br>                <span class="hljs-keyword">if</span> norm != <span class="hljs-number">0</span>:<br>                    r_at = alpha * param.grad / norm<br>                    param.data.add_(r_at)<br>                    param.data = self.project(name, param.data, epsilon)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">restore</span>(<span class="hljs-params">self, emb_name=<span class="hljs-string">&#x27;emb.&#x27;</span></span>):<br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name: <br>                <span class="hljs-keyword">assert</span> name <span class="hljs-keyword">in</span> self.emb_backup<br>                param.data = self.emb_backup[name]<br>        self.emb_backup = &#123;&#125;<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">project</span>(<span class="hljs-params">self, param_name, param_data, epsilon</span>):<br>        r = param_data - self.emb_backup[param_name]<br>        <span class="hljs-comment"># 如果扰动超出约束空间，就映射回去</span><br>        <span class="hljs-keyword">if</span> torch.norm(r) &gt; epsilon:<br>            r = epsilon * r / torch.norm(r)<br>        <span class="hljs-keyword">return</span> self.emb_backup[param_name] + r<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">backup_grad</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad:<br>                self.grad_backup[name] = param.grad.clone()<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">restore_grad</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad:<br>                param.grad = self.grad_backup[name]<br></code></pre></td></tr></table></figure><p>调用方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">pgd = PGD(model)<br><span class="hljs-keyword">for</span> batch_input, batch_label <span class="hljs-keyword">in</span> data:<br>    <span class="hljs-comment"># 正常训练</span><br>    loss = model(batch_input, batch_label)<br>    loss.backward() <span class="hljs-comment"># 反向传播，得到正常的grad</span><br>    pgd.backup_grad()<br>    <span class="hljs-comment"># 对抗训练</span><br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(pgd.steps):<br>        pgd.attack(is_first_attack=(t==<span class="hljs-number">0</span>)) <span class="hljs-comment"># first attack时备份param.data</span><br>        <span class="hljs-keyword">if</span> t != pgd.steps -<span class="hljs-number">1</span>:<br>            model.zero_grad()<br>        <span class="hljs-keyword">else</span>:<br>            pgd.restore_grad()<br>        loss_adv = model(batch_input, batch_label)<br>        loss_adv.backward() <span class="hljs-comment"># 反向传播，并在正常的grad基础上，累加对抗训练的梯度</span><br>    pgd.restore() <span class="hljs-comment"># 恢复embedding参数</span><br>    <span class="hljs-comment"># 梯度下降，更新参数</span><br>    optimizer.step()<br>    model.zero_grad()<br></code></pre></td></tr></table></figure><blockquote><p>代码参考自：https://zhuanlan.zhihu.com/p/91269728</p></blockquote><h3 id="free-adversarial-trainingfreeat">3.3 <a href="https://arxiv.org/pdf/1904.12843.pdf">Free AdversarialTraining(FreeAT)</a></h3><p>​ 从<strong>FGM</strong>到<strong>PGD</strong>，主要优化了扰动 <span class="math inline">\(r_{adv}\)</span>的计算，但是计算量也增加了。在<strong>FGM</strong>中，每个样本每次迭代需要计算两次（一次<span class="math inline">\(x\)</span>，一次<span class="math inline">\(x+r_{adv}\)</span>）,而<strong>PGD</strong>中则要计算<span class="math inline">\(K+1\)</span>次，消耗了更多的计算资源，而且在梯度下降时只利用了参数的梯度，梯度提升时只利用输入的梯度，有没有办法把计算出来的梯度和输入的梯度同时利用上呢？这就是<strong>FreeAT</strong>的核心思想。</p><p><strong>PGD</strong>采用的是对每个样本求K次梯度，K步走完后，才重新计算一次梯度用来更新模型参数，而<strong>FreeAT</strong>则是每走一步求一次梯度，更新一次模型参数，具体差别可以用下图来表示：</p><figure><img src="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/FreeAT.png" alt="FreeAT"><figcaption aria-hidden="true">FreeAT</figcaption></figure><p>​这样一来，<strong>FreeAT</strong>中模型参数更新的次数是普通训练的K倍，所以他把总体的epoch次数除以K来保证梯度计算次数跟普通训练的一样。这样会带来一个问题，一个mini-batch的样本被模型训练了K遍，可能影响到模型收敛的效果（论文中作者用实验结果表示这种担心不太必要）。</p><p>实现上，<strong>FreeAT</strong>在计算下一步扰动的梯度时，复用上一步的梯度，r的更新公式为：<span class="math display">\[r_{t+1} = r_t + \epsilon * sign(g),\quad g = \nabla_{x}L(\theta,x,y)\]</span></p><p>主要思路如下：</p><blockquote><p>初始化r=0 对于epoch=1...N/m: 对于每个x: 对于每步m:1.利用上一步的r，计算x+r的前后向loss，得到梯度 2.根据梯度更新参数3.根据梯度更新r</p></blockquote><h3 id="free-large-batchfreelb">3.4 <a href="https://arxiv.org/pdf/1909.11764.pdf">FreeLarge-Batch(FreeLB)</a></h3><p>​ 可以看到在<strong>PGD</strong>中只使用了最后一步<span class="math inline">\(x+r_{adv}\)</span>输出的梯度，<strong>FreeLB</strong>在这里做了改进，它取了每次迭代更新<span class="math inline">\(r_{adv}\)</span>过程中梯度的平均值，相当于在最大化扰动过程中，把原本的<span class="math inline">\(\max \limits_{r_{adv}\in S}L(\theta,x+r_{adv}, y)\)</span> 变成了 <span class="math inline">\(\frac{1}{K}\sum\limits_{t=0}^{K-1}\max\limits_{r_{t}\in S}L(\theta, x+r_{t}, y)\)</span>，其中 <span class="math inline">\(K\)</span> 为迭代的步数。</p><p>代码思路如下：</p><blockquote><p>对于每个x: 1.通过均匀分布初始化r，梯度g为0 对于每步t=1...K:2.根据x+r计算前后向，累计梯度g 3.更新r 4.根据g/K更新梯度</p></blockquote><p>论文中作者还指出<strong>对抗训练和dropout不能同时使用</strong>，dropout相当于改变了网络结构，会影响扰动<span class="math inline">\(r_{adv}\)</span> 的计算。</p><h3 id="smoothness-inducing-adversarial-reregularizationsmart">3.5 <a href="https://arxiv.org/pdf/1911.03437.pdf">SMoothness-inducingAdversarial ReRegularization(SMART)</a></h3><p>​前面提到的对抗训练方法都是针对添加扰动后传回的梯度进行处理，并没有在损失函数上做改动，而<strong>SMART</strong>则是在Loss上添加了一个正则项：<strong>Smoothness-inducingAdversarialRegularization</strong>，目的是在一定的范围内，找到对模型影响最大的扰动<span class="math inline">\(r\)</span>： <span class="math display">\[\mathcal{R}_s(\theta)=\frac{1}{n}\sum\limits_{i=1}^n \max\limits_{r_{i}\in S}l_s(f(x_i+r_{i};\theta), f(x_i;\theta))\]</span> 其中<span class="math inline">\(l_s\)</span>为<strong>对称的KL散度</strong></p><p><span class="math display">\[l_s(P,Q) = D_{KL}(P||Q) + D_{KL}(Q||P)\]</span></p><p>模型的优化目标就在于 <span class="math display">\[\mathop{argmin}_\limits \theta \mathcal{F}(\theta) =\mathop{argmin}_\limits \theta \bigg(\mathcal{L}(\theta) +\lambda_s\mathcal{R}_s(\theta)\bigg)\]</span></p><p>为了求解（11）式，作者还提出了<strong>Bregman Proximal PointOptimization</strong>优化方法，对于第<span class="math inline">\(t+1\)</span>轮迭代： <span class="math display">\[\theta_{t+1} = \mathop{argmin}\limits_{\theta}\bigg(\mathcal{F}(\theta)+ \mu\mathcal{D}_{Breg}(\theta,\theta_t)\bigg)\]</span> 其中<span class="math inline">\(\theta_0\)</span>为预训练模型的参数，<span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>（布雷格曼散度）的定义如下：<span class="math display">\[\mathcal{D}_{Breg}(\theta,\theta_t)=\frac{1}{n}\sum\limits_{i=1}^nl_s(f(x_i;\theta), f(x_i;\theta_t))\]</span> <span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>也可以看做是一个正则项，用来防止模型参数更新的幅度过大。</p><p>在这两项正则项下，模型的最终损失函数可以写成如下形式： <span class="math display">\[\mathcal{F}(\theta) = \mathcal{L}(\theta) +\lambda_s\mathcal{R}_s(\theta) +\mu\mathcal{D}_{Breg}(\theta,\theta_t)\]</span> 最终的优化策略如下：</p><blockquote><p>对于第t轮迭代：</p><p>1.备份模型参数<span class="math inline">\(\theta\)</span>，作为计算<span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>中的<span class="math inline">\(\theta_t\)</span>；</p><p>2.对于每个batch内的第 <span class="math inline">\(i\)</span>个数据：</p><p>​ 使用正态分布随机初始化扰动<span class="math inline">\(r_i\)</span>，结合<span class="math inline">\(x_i\)</span>得到对抗样本 <span class="math inline">\(x_i+r_i\)</span>；</p><p>​ 对于m个小步：</p><p>​ 计算扰动下的梯度<span class="math inline">\(\widetildeg\)</span>；</p><p>​ 基于<span class="math inline">\(\widetildeg\)</span>和学习率更新对抗样本<span class="math inline">\(x_i+r_i\)</span>；</p><p>​ 基于对抗样本<span class="math inline">\(x_i+r_i\)</span>重新计算梯度，更新模型参数<span class="math inline">\(\theta\)</span>；</p><p>3.更新<span class="math inline">\(\theta_t,\quad\theta_t=(1-\beta)\theta + \beta\theta_t\)</span>，<span class="math inline">\(\beta\)</span>为动量参数。</p></blockquote><p>总体来说<strong>SMART</strong>的思路主要分为两部分：</p><p>1.训练过程中加入对embedding的随机扰动，要求模型的输出尽可能与扰动前的概率保持一致；</p>2.在模型更新参数时，修改优化器（Adam）的结果，要求模型参数与预训练时的参数分布相近，尽可能少改变。<section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Explaining and HarnessingAdversarial Examples. https://arxiv.org/abs/1412.6572<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>Adversarial Training Methodsfor Semi-Supervised Text Classification.https://arxiv.org/abs/1605.07725<a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>对称KL散度又称JS散度，<span class="math inline">(JSD(P||Q) = KL(P||M) + KL(Q||M),M=(p+Q))</span>，这里与传统的JS散度略有不同。<a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对抗训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/06/21/Hello/"/>
    <url>/2022/06/21/Hello/</url>
    
    <content type="html"><![CDATA[<p>Welcome to My Blog!</p>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>其他</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对比学习总结</title>
    <link href="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <url>/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h2 id="对比学习总结">对比学习总结</h2><h3 id="cv">1. CV</h3><h4 id="百花齐放">百花齐放</h4><p><strong><a href="https://arxiv.org/pdf/1805.01978.pdf">InstDisc</a></strong></p><p>提出了<strong>个体判别任务</strong>和<strong>memorybank</strong>（字典形式）。正样本为自己，负样本为所有其他图片，负样本的特征存放在memorybank中。loss使用的是NCE loss。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608103708444.png" alt="InstDisc"><figcaption aria-hidden="true">InstDisc</figcaption></figure><p>skills: 由于memory bank里的特征数量通常较大，<strong>ProximalRegularizatio</strong>对memorybank里的特征进行动量更新，节省时间和内存。</p><p><a href="https://arxiv.org/pdf/1904.03436.pdf">InvaSpread</a></p><p>基本的对比学习，相似的物体特征应该保持不变性，不相似的物体特征应该尽量分散开。选取了<strong>个体判别任务</strong>。正样本为自己经过数据增强后的图片，负样本为batchsize里其他图片（包括原始图片和其数据增强后的图片），这样的好处在于，可以只用一个编码器去做端到端的训练。使用的loss为NCEloss的变体。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608105200188.png" alt="InvaSpread"><figcaption aria-hidden="true">InvaSpread</figcaption></figure><p><a href="https://arxiv.org/pdf/1807.03748.pdf">CPC</a></p><p>选取了预测型的任务来做对比学习，对于模型的预测结果(z_t+1)来说，正样本为未来时刻的输入（x_t+1)通过编码器的输出，负样本为任意输入通过编码器的输出。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608105544159.png" alt="CPC"><figcaption aria-hidden="true">CPC</figcaption></figure><p><a href="https://arxiv.org/pdf/1906.05849.pdf">CMC</a></p><p>多视角的对比学习，目的是增大所有视角之间的互信息，对于某个物体来说，正样本为其在其他视角（模态）下的信息，负样本为其他与物体</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608110638390.png" alt="CMC"><figcaption aria-hidden="true">CMC</figcaption></figure><h4 id="cv双雄">CV双雄</h4><p><a href="https://arxiv.org/pdf/1911.05722.pdf">MoCov1</a></p><p>把之前对比学习的方法都归纳成一个字典查询的问题，思路和<strong><a href="https://arxiv.org/pdf/1805.01978.pdf">InstDisc</a></strong>很类似。文章中提出了两个东西：<strong>队列</strong>和<strong>动量编码器</strong>，队列用来存储负样本的特征，动量编码器用来动态更新encoder，而不是动量的去更新负样本的特征。loss用的是infoNCE loss。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608111328200.png" alt="MoCov1"><figcaption aria-hidden="true">MoCov1</figcaption></figure><p>创新点：<strong>动量编码器</strong>，后续对比学习的工作还在沿用这个skill。</p><p><a href="https://arxiv.org/pdf/2002.05709.pdf">SimCLRv1</a></p><p>正负样本的构造方式与<a href="https://arxiv.org/pdf/1904.03436.pdf">InvaSpread</a>相同，正样本为数据增强后的样本，负样本为batch里其他及其数据增强后的样本，simclr与InvaSpread的区别在于使用了更多的数据增强方式，在encoder后面增加了一个g函数(全连接层)，用了更大的batchsize（4096）。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608111947184.png" alt="SimCLRv1"><figcaption aria-hidden="true">SimCLRv1</figcaption></figure><p>创新点：在编码器后面加了一个mlp层（projector），效果有了很大的提升。</p><p><a href="https://arxiv.org/pdf/2003.04297.pdf">MoCov2</a></p><p>在原来的moco上面做了一些简单的改动，借鉴了simclr里面的一些技术，使用了更多的数据增强方式，以及在编码器后面加了一个mlp层，同时模型的训练epoch数也增加了（由200增加到800）。通常来说，无监督模型或者大型模型，训练越久模型效果越好。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608113045353.png" alt="MoCov2"><figcaption aria-hidden="true">MoCov2</figcaption></figure><p><a href="https://arxiv.org/pdf/2006.10029.pdf">SimCLRv2</a></p><p>文章主要在讲大模型如何去做半监督学习。相比于simclrv1，论文的主要改动在于：换了一个更大的网络，实验了不同深度的mlp层(projectionhead)，使用了动量编码器。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608113611143.png" alt="SimCLRv2"><figcaption aria-hidden="true">SimCLRv2</figcaption></figure><p><a href="https://arxiv.org/pdf/2006.09882.pdf">SWaV</a></p><p>将对比学习和聚类的方法融合在了一起，将样本去跟负样本的聚类中心做对比。基本流程是样本x通过数据增强得到<span class="math inline">\(x_1, x_2\)</span>，再通过一个编码器<span class="math inline">\(f(\theta)\)</span>得到两个特征<span class="math inline">\(z_1,z_2\)</span>，接下来在与聚类中心c进行计算得到groundtruth <span class="math inline">\(Q_1,Q_2\)</span>，对<span class="math inline">\(Q_1, Q_2\)</span>进行训练。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608154756024.png" alt="SWaV"><figcaption aria-hidden="true">SWaV</figcaption></figure><p>skill: Multi-crop</p><h4 id="不用负样本">不用负样本</h4><p><a href="https://arxiv.org/pdf/2006.07733.pdf">BYOL</a></p><p>样本x通过两次不同的数据增强得到两个样本<span class="math inline">\(v,v&#39;\)</span>，再通过两个不同的编码器<span class="math inline">\(f(\theta)\)</span>（结构一样，参数不一样）得到两个特征<span class="math inline">\(y_{\theta},y&#39;_{\epsilon}\)</span>，然后再通过两个不同的mlp层得到<span class="math inline">\(z_{\theta}, z&#39;_{\epsilon}\)</span>，最终<span class="math inline">\(z_{\theta}\)</span>通过一个全连接层<span class="math inline">\(q_{\theta}\)</span>（网络结构与<span class="math inline">\(g_{\theta}\)</span>相同）得到<span class="math inline">\(q_{\theta}(z_{\theta})\)</span>，通过让<span class="math inline">\(q_{\theta}(z_{\theta})\)</span>去学习<span class="math inline">\(sg(z&#39;_{\epsilon})\)</span>来完成训练。其中下面的编码器和projector采用的是动量更新（类似于MoCo）。loss使用的是mseloss</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608160558770.png" alt="BYOL"><figcaption aria-hidden="true">BYOL</figcaption></figure><p>注：论文中使用的mlp层结构如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MLP</span>(<span class="hljs-params">dim, projection_size, hidden_size=<span class="hljs-number">4096</span></span>):<br>    <span class="hljs-keyword">return</span> nn.Sequential(<br>        nn.Linear(dim, hidden_size),<br>        nn.BatchNorm1d(hidden_size),<br>        nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>        nn.Linear(hidden_size, projection_size)<br>    )<br><br></code></pre></td></tr></table></figure><p>若去掉mlp层中的BatchNorm部分，模型效果会大大降低，原因在于去掉后会影像模型的初始化参数。</p><p><a href="https://arxiv.org/pdf/2011.10566.pdf">SimSiam</a></p><p>思路跟BYOL类似，样本x通过两次数据增强得到<span class="math inline">\(x_1,x_2\)</span>，x1通过编码器f和一个projector得到h，通过h去学习x2由编码器f解码出来的特征来完成训练，其中stop-grad至关重要。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608160528262.png" alt="SimSiam"><figcaption aria-hidden="true">SimSiam</figcaption></figure><p>simsiam与其他模型的对比如下：</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608164315837.png" alt="simsiam与其他模型的对比"><figcaption aria-hidden="true">simsiam与其他模型的对比</figcaption></figure><h4 id="transformer">Transformer</h4><p><a href="https://arxiv.org/pdf/2104.02057.pdf">MoCov3</a></p><p>模型网络结构融合了MoCo V2和SimSiam</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608165835942.png" alt="MoCov3"><figcaption aria-hidden="true">MoCov3</figcaption></figure><p>trick：MoCo V3将编码器由原来的resnet换成了VIT，且在训练时将VIT的patch projection层冻住（batchsize变大效果反而变差的问题在于patchprojection层在训练时梯度过大）。</p><p><a href="https://arxiv.org/pdf/2104.14294.pdf">DINO</a></p><p>思路和训练过程跟MoCo V3类似。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608170630626.png" alt="DINO"><figcaption aria-hidden="true">DINO</figcaption></figure><p><a href="https://openai.com/blog/clip/">CLIP</a></p><p>将文本信息和图片信息相结合。训练时，配对的图片和描述文本为正样本，不配对的图片和文本描述为负样本，然后利用对比学习来训练。预测时，通过prompt来构造文本描述，然后计算每个选项的置信度。论文的创新点在于：1.对于分类或检测任务，训练时不用再指定类别，只要在训练数据中出现过的类别，模型都可以通过prompt的形式来预测出来；2.打通了文本和图像的限制，文本编码器和图像编码器都可以使用transformer结构，为后续多模态模型的发展提供了统一框架的可能。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608170005523.png" alt="CLIP"><figcaption aria-hidden="true">CLIP</figcaption></figure><h4 id="总结">总结</h4><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608174138168.png" alt="对比学习总结"><figcaption aria-hidden="true">对比学习总结</figcaption></figure><h2 id="nlp">2. NLP</h2><p>SimCSE</p><p>ESimsce</p><p>ConSERT</p><p>SCCL</p><p>ERICA</p><p>QuantiDCE</p><p>注：本文总结自李沐老师的<a href="https://www.bilibili.com/video/BV19S4y1M7hm?spm_id_from=333.999.0.0">视频</a>和<a href="https://github.com/mli/paper-reading#contrastive_learning">github</a>。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对比学习</tag>
      
      <tag>CV</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
