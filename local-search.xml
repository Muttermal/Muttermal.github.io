<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Cypher基本语法</title>
    <link href="/2022/08/15/Cypher%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
    <url>/2022/08/15/Cypher%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="cypher基本语法">Cypher基本语法</h1><p align="center"><a><img src="https://img.shields.io/badge/neo4j-Cypher-ff69b4"></a></p><p><code>Cypher</code>基本语法整理，更多信息见<a href="https://graphacademy.neo4j.com/courses/cypher-fundamentals/1-reading/">官网</a></p><h2 id="基本格式">基本格式</h2><ul><li><strong>节点(Nodes)</strong>用 <code>()</code> 来表示；</li><li>使用冒号来表示<strong>标签(labels)</strong>，如<code>(:Person)</code>;</li><li>节点之间的<strong>关系(Relationships)</strong>用两个破折号来表示，如<code>(:Person)--(:Movie)</code>;</li><li>使用大于小于符号来表示关系的指向，如<code>(:Person)--&gt;(:Movie)</code>;</li><li>关系的<strong>类型(type)</strong>在破折号之间使用方括号来表示，如<code>[:ACTED_IN]</code>;</li><li>搜索条件中的<strong>属性(properties)</strong>支持json格式，即使用键值对来表示，如<code>&#123;name: 'Tom Hanks'&#125;</code>;</li></ul><p>一个<code>Cypher</code>搜索示例如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token punctuation">(</span>m<span class="token operator">:</span><span class="token class-name">Movie</span> <span class="token punctuation">&#123;</span>title<span class="token operator">:</span> <span class="token string">'Cloud Atlas'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span> <span class="token operator">&lt;-</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-</span><span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="查询语法">查询语法</h2><ul><li><p><code>MATCH</code>:从图中检索数据；</p></li><li><p><code>RETURN</code>:返回检索到的节点；</p></li><li><p><code>WHERE</code>:过滤搜索条件；</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span><span class="token punctuation">)</span><span class="token keyword">WHERE</span> p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">'Tom Hanks'</span> <span class="token keyword">OR</span> p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">'Rita Wilson'</span><span class="token keyword">RETURN</span> p<span class="token punctuation">.</span>name<span class="token punctuation">,</span> p<span class="token punctuation">.</span>born<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure></p><blockquote><p>在<code>Cypher</code>中,标签、属性的keys和变量都是大小写敏感的，关键字是大小写不敏感的。推荐的命名方式如下：</p><ul><li>标签使用 <strong>CamelCase</strong> 形式；</li><li>属性keys和变量使用 <strong>camelCase</strong> 形式；</li><li>Cypher keywords使用 <strong>UPPERCASE</strong> 形式。</li></ul></blockquote><p>除了使用<code>WHERE</code>对属性进行过滤搜索，关系同样也可以进行过滤：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-Cypher" data-language="Cypher"><code class="language-Cypher">MATCH (p: Person &#123;name: &quot;Tom Hanks&quot;&#125;) -[:ACTED_IN]-&gt;(m: Movie)RETURN m.title<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p><p>二者也可以混合使用</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span><span class="token punctuation">)</span><span class="token keyword">WHERE</span> p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"Tom Hanks"</span><span class="token keyword">RETURN</span> m<span class="token punctuation">.</span>title<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure></p><p><code>WHERE</code>查询中也支持<code>&lt;=,&gt;=,AND,OR,IS NOT,IN</code>等逻辑运算字符，还有一些支持的关系字符如下：<code>STARTS WITH</code><code>ENDS WITH</code><code>CONTAINS</code>。以及一些函数：<code>toLower()</code><code>toUpper()</code> <code>exists()</code>。</p><p>有时关系(Relationships)中也包含属性(properties)，可以通过如下方式查询满足条件的关系：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token punctuation">[</span>r<span class="token operator">:</span> <span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span><span class="token punctuation">)</span><span class="token keyword">WHERE</span> m<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">"The Matrix"</span> <span class="token keyword">AND</span> <span class="token string">"Neo"</span> <span class="token keyword">IN</span> r<span class="token punctuation">.</span>roles<span class="token keyword">RETURN</span> p<span class="token punctuation">.</span>name<span class="token punctuation">,</span> r<span class="token punctuation">.</span>roles<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure></p><p>若不知道某个节点或关系有哪些属性，可通过<code>keys()</code>来查看：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span><span class="token punctuation">)</span><span class="token keyword">RETURN</span> p<span class="token punctuation">.</span>name<span class="token punctuation">,</span> <span class="token function">keys</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token comment">//没有指定节点时，会返回数据库中所有满足条件的节点</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p><p>也可通过以下方式来查看图数据库中所有节点和关系的属性有哪些：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">CALL</span> db<span class="token punctuation">.</span><span class="token function">propertyKeys</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure></p></li></ul><h2 id="增删数据">增删数据</h2><ul><li><p><code>MERGE</code>:在数据库中创建一个pattern，创建时需要指定节点的label，以及至少一个作为主键的属性；</p></li><li><p><code>CREATE</code>:也可以创建节点，但是它不会搜索数据库中包不包含这个新节点，所以如果确定数据库里不包含即将创建的新节点时，推荐使用<code>CREATE</code>；</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">"Katie Holmes"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span> <span class="token punctuation">&#123;</span>title<span class="token operator">:</span> <span class="token string">"The Dark Knight"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">RETURN</span> p<span class="token punctuation">,</span> m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure></p></li><li><p>创建属性时，首先要指定相关的节点，然后必须指定<strong>关系类型和方向</strong>(方向不确定时也可以不指定)；</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">"Michael Cain"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span> <span class="token punctuation">&#123;</span>title<span class="token operator">:</span> <span class="token string">"The Dark Knight"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">[</span><span class="token operator">:</span><span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure></p><p>也可以在创建节点的时候创建关系，如下：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>p<span class="token operator">:</span> <span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">"Emily Blunt"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">[</span><span class="token operator">:</span> <span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span> <span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span> <span class="token punctuation">&#123;</span>title<span class="token operator">:</span> <span class="token string">"A Quiet Place"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">RETURN</span> p<span class="token punctuation">,</span> m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p></li><li><p>更新属性有两种方法，一种是使用上述的创建节点和关系的方法来更新属性，另一种是使用<code>SET</code>来设置属性值:</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">[</span>r<span class="token operator">:</span> <span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token operator">:</span> <span class="token class-name">Movie</span><span class="token punctuation">)</span><span class="token keyword">WHERE</span> p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"Michael Cain"</span> <span class="token keyword">AND</span> m<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">"The Dark Knight"</span><span class="token keyword">SET</span> r<span class="token punctuation">.</span>roles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Alfred Penny"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> r<span class="token punctuation">.</span>years <span class="token operator">=</span> <span class="token number">2008</span><span class="token keyword">RETURN</span> p<span class="token punctuation">,</span> r<span class="token punctuation">,</span> m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure></p><p>移除属性时可以使用<code>REMOVE</code>或将属性值设置为<code>null</code></p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">[</span>r<span class="token operator">:</span><span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token operator">:</span><span class="token class-name">Movie</span><span class="token punctuation">)</span><span class="token keyword">WHERE</span> p<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">'Michael Cain'</span> <span class="token keyword">AND</span> m<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">'The Dark Knight'</span><span class="token keyword">REMOVE</span> r<span class="token punctuation">.</span>roles<span class="token keyword">SET</span> p<span class="token punctuation">.</span>born <span class="token operator">=</span> <span class="token boolean">null</span><span class="token keyword">RETURN</span> p<span class="token punctuation">,</span> r<span class="token punctuation">,</span> m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></p></li><li><p><code>MERGE</code>会先搜索节点，若节点不存在则创建，若存在则进行<code>MATCH</code>操作,可通过<code>ON CREATE SET</code>和<code>ON MATCH SET</code>来区分这两种情况：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">"Mckenna Grace"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">ON</span> <span class="token keyword">CREATE</span> <span class="token keyword">SET</span> p<span class="token punctuation">.</span>createdAt <span class="token operator">=</span> <span class="token function">datetime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">ON</span> <span class="token keyword">MATCH</span> <span class="token keyword">SET</span> p<span class="token punctuation">.</span>updatedAt <span class="token operator">=</span> <span class="token function">datetime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">SET</span>p<span class="token punctuation">.</span>born <span class="token operator">=</span> <span class="token number">2006</span><span class="token keyword">RETURN</span> p<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></p><ul><li><code>DELETE</code>:删除操作，可以删除节点、关系、属性和标签，删除标签、属性可以使用上述<code>REMOVE</code>来进行操作。</li></ul><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MERGE</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">'Jane Doe'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">[</span>r<span class="token operator">:</span><span class="token relationship property">ACTED_IN</span><span class="token punctuation">]</span><span class="token operator">-></span><span class="token punctuation">(</span>m<span class="token operator">:</span><span class="token class-name">Movie</span> <span class="token punctuation">&#123;</span>title<span class="token operator">:</span> <span class="token string">'The Matrix'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">DELETE</span> r<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p><p>如果一个节点具有指向它的性质，则不能被删除，先要删除关系才能删除该节点，此时可以进行如下操作：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>p<span class="token operator">:</span><span class="token class-name">Person</span> <span class="token punctuation">&#123;</span>name<span class="token operator">:</span> <span class="token string">"Jane Doe"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token keyword">DETACH</span> <span class="token keyword">DELETE</span> p <span class="token comment">// 先删除指向它的关系，再删除节点</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p><p>删除所有节点操作：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-cypher" data-language="cypher"><code class="language-cypher"><span class="token keyword">MATCH</span> <span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token keyword">DETACH</span> <span class="token keyword">DELETE</span> n <span class="token comment">//谨慎操作</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cypher</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker学习笔记</title>
    <link href="/2022/07/13/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/07/13/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="docker学习笔记1">Docker学习笔记<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Docker——从入门到实践](https://yeasy.gitbook.io/docker_practice/)">[1]</span></a></sup></h1><p align="center"><a><img src="https://img.shields.io/badge/Docker-学习笔记-ff69b4"></a></p><h2 id="docker简介">1.🐳Docker简介</h2><p>官方解释：</p><blockquote><p>​ Docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的<a href="https://baike.baidu.com/item/镜像/1574">镜像</a>中，然后发布到任何流行的<a href="https://baike.baidu.com/item/Linux">Linux</a>或<a href="https://baike.baidu.com/item/Windows/165458">Windows</a>操作系统的机器上，也可以实现<a href="https://baike.baidu.com/item/虚拟化/547949">虚拟化</a>。容器是完全使用<a href="https://baike.baidu.com/item/沙箱/393318">沙箱</a>机制，相互之间不会有任何接口。</p></blockquote><p>自我理解：</p><blockquote><p>​优化版的虚拟机，根据自己对于开发环境的需求来通过docker创建相应的虚拟环境。docker轻巧方便，互相之间没有依赖，用完即删，导出方便，极大简化了环境配置的问题。</p></blockquote><h2 id="基础概念">2.🐋基础概念</h2><p>Docker的三个最基础的概念为：</p><ul><li><strong>镜像(Image)</strong></li><li><strong>容器(Container)</strong></li><li><strong>仓库(Repository)</strong></li></ul><h4 id="镜像">镜像</h4><p>​可以理解成是一个root文件系统，不仅包含容器运行时所需要的程序、库、资源、配置文件等，还包含一些配置参数（如环境变量、用户）等。镜像中不包含动态数据，其内容在构建化后将不在改变。</p><p>​镜像采用了<strong>分层存储</strong>的架构，在构建时是一层一层构建的，每一层构建完成后不再发生改变。</p><h4 id="容器">容器</h4><p>​容器即为实例化后的镜像，镜像是静态的定义，容器则是镜像运行时的实体。容器可以被创建、启动、停止、删除等。容器运行时，以镜像为基础层，然后在其上创建一个储存层来储存数据，数据卷的身存周期独立于容器，容器被删除或重启时，数据卷中数据不会丢失。</p><h4 id="仓库">仓库</h4><p>​一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过<code>&lt;仓库名&gt;:&lt;标签&gt;</code>的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以<code>latest</code>作为默认标签。如<code>ubuntu:16.04</code>，仓库名为ubuntu，16.04为标签。</p><p>​ 一个 <strong>Docker Registry</strong> 中可以包含多个<strong>仓库</strong>（<code>Repository</code>）；每个仓库可以包含多个<strong>标签</strong>（<code>Tag</code>）；每个标签对应一个镜像。官方的DockerRegistry见<a href="https://hub.docker.com/">Docker Hub</a>。</p><h2 id="基本命令">3.🐟基本命令</h2><p>​ 安装教程：<a href="https://docs.docker.com/get-docker/">官方安装教程</a>，<a href="https://yeasy.gitbook.io/docker_practice/install">中文安装教程</a></p><h5 id="获取镜像">获取镜像</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> pull <span class="token punctuation">[</span>选项<span class="token punctuation">]</span> <span class="token punctuation">[</span>Docker Registry 地址<span class="token punctuation">[</span>:端口号<span class="token punctuation">]</span>/<span class="token punctuation">]</span>仓库名<span class="token punctuation">[</span>:标签<span class="token punctuation">]</span><span class="token comment"># docker pull ubuntu:18.04</span><span class="token comment"># docker pull centos</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><blockquote><p>Docker 镜像仓库地址：地址的格式一般是<code>&lt;域名/IP&gt;[:端口号]</code>。默认地址是 DockerHub(<code>docker.io</code>)。</p><p>仓库名：两段式名称，即<code>&lt;用户名&gt;/&lt;软件名&gt;</code>。对于 DockerHub，如果不给出用户名，则默认为<code>library</code>，也就是官方镜像。不指定标签是，默认为"latest"</p></blockquote><h5 id="镜像信息">镜像信息</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> image <span class="token function">ls</span><span class="token comment"># 列出所有镜像</span><span class="token function">docker</span> image <span class="token function">ls</span> ubuntu<span class="token comment"># 指定仓库名或标签，列出指定镜像</span><span class="token function">docker</span> system <span class="token function">df</span><span class="token comment"># 查看镜像体积</span><span class="token function">docker</span> image <span class="token function">ls</span> -f <span class="token assign-left variable">since</span><span class="token operator">=</span>mongo:3.2<span class="token comment"># -f为filter，通过过滤条件列出所需镜像</span><span class="token function">docker</span> image <span class="token function">ls</span> -f <span class="token assign-left variable">before</span><span class="token operator">=</span>mongo:3.2<span class="token function">docker</span> image <span class="token function">ls</span> -f <span class="token assign-left variable">label</span><span class="token operator">=</span>com.example.version<span class="token operator">=</span><span class="token number">0.1</span><span class="token function">docker</span> image <span class="token function">ls</span> -q<span class="token comment"># 列出镜像ID</span><span class="token function">docker</span> image <span class="token function">ls</span> --format <span class="token string">"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;"</span><span class="token comment"># 根据指定格式来显示信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h5 id="删除镜像">删除镜像</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> image <span class="token function">rm</span> <span class="token number">501</span><span class="token comment"># 删除镜像，一般使用image ID的三个以上字符即可指定相应镜像</span><span class="token function">docker</span> image <span class="token function">rm</span> centos<span class="token comment"># 使用镜像名或标签来删除指定镜像</span>ocker image <span class="token function">rm</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">docker</span> image <span class="token function">ls</span> -q redis<span class="token variable">)</span></span><span class="token comment"># 组合命令</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h5 id="容器运行">容器运行</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run -it ubuntu:18.04<span class="token function">docker</span> run ubuntu:18.04 /bin/echo <span class="token string">'Hello world'</span><span class="token comment">#启动镜像并输Hello world</span><span class="token function">docker</span> container start ubuntu:18.04<span class="token comment"># 启动已终止的镜像</span><span class="token function">docker</span> run -d ubuntu:18.04 /bin/sh -c <span class="token string">"while true; do echo hello world; sleep 1; done"</span><span class="token comment"># 后台运行，命令执行结果不会打印在控制台上</span><span class="token function">docker</span> container <span class="token function">ls</span><span class="token comment"># 查看容器信息，包括容器ID，具体命令等</span><span class="token function">docker</span> container logs <span class="token punctuation">[</span>container ID or NAMES<span class="token punctuation">]</span><span class="token comment"># 查看容器后台运行结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><blockquote><p>docker run:运行的基础命令，后面可以接其他命令。</p><p>-it:这是两个参数，-i表示交互式操作，-t表示终端。</p><p>ubuntu:18.04为镜像名称。</p><p>终端开启后，可通过exit命令退出容器。一般情况下使用exit会终止容器，若想退出而不终止容器，可使用快捷键<code>ctrl</code>+<code>P</code>+<code>Q</code>。</p></blockquote><h5 id="容器终止">容器终止</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> container stop ubuntu:18.04<span class="token comment"># 终止正在运行的镜像</span><span class="token function">docker</span> container <span class="token function">ls</span> -a <span class="token comment"># 查看容器的状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h5 id="进入容器">进入容器</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> attach 243c <span class="token comment"># 进入id为243c的容器</span><span class="token function">docker</span> <span class="token builtin class-name">exec</span> -it <span class="token number">8331</span> <span class="token function">bash</span><span class="token comment"># 进入id为69d1的容器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><blockquote><p>使用<code>docker attach</code>进入容器，输入<code>exit</code>时容器会停止；使用<code>exec</code>进入容器则不会，推荐使用<code>exec</code>命令。容器ID和镜像ID是不同的，容器ID可用<code>docker container ls</code>来查看。</p></blockquote><h5 id="容器导出与导入">容器导出与导入</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token builtin class-name">export</span> 7691a814370e <span class="token operator">></span> ubuntu.tar<span class="token comment"># 导出container为7691a814370e的容器快照</span><span class="token function">cat</span> ubuntu.tar <span class="token operator">|</span> <span class="token function">docker</span> <span class="token function">import</span> - test/ubuntu:v1.0<span class="token comment"># 通过容器快照来导入</span><span class="token function">docker</span> <span class="token function">import</span> http://example.com/exampleimage.tgz example/imagerepo<span class="token comment"># 通过目录来导入</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h5 id="容器删除">容器删除</h5><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> container <span class="token function">rm</span> trusting_newton<span class="token comment"># 删除一个处于终止状态的容</span><span class="token function">docker</span> container prune<span class="token comment"># 清理掉所有处于终止状态的容器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>私有仓库的配置暂未用到，这里先不做整理。</p><h2 id="dockerfile">4.🎈DockerFile</h2><p>​ Dockerfile是一个文本文件，其内包含了一条条的<strong>指令(Instruction)</strong>，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。我们可以把每一层修改、安装、构建、操作的命令都写入Dockerfile，用Dockerfile来构建、定制镜像。</p><p>​ 我们先来看一个示例，再来分析每个命令的含义和具体语法。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">FROM</span> redis_gpu:latest</span><span class="token instruction"><span class="token keyword">LABEL</span> maintainer=<span class="token string">"Erwan BERNARD https://github.com/edmBernard/DockerFiles"</span></span><span class="token instruction"><span class="token keyword">RUN</span> pip3 --no-cache-dir install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html</span><span class="token instruction"><span class="token keyword">RUN</span> pip3 --no-cache-dir install onnx protobuf future</span><span class="token instruction"><span class="token keyword">CMD</span> [<span class="token string">"/bin/bash"</span>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>DockerFile中关键字及其含义如下：</p><p><code>From</code>:指定基础镜像，如:FROM redis_gpu:latest。</p><p><code>RUN</code>:<code>RUN</code>命令格式有两种，一种是执行命令行的命令，另一种是函数调用的格式。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">RUN</span> pip install torch# shell 格式</span><span class="token instruction"><span class="token keyword">RUN</span> [<span class="token string">"可执行文件"</span>, <span class="token string">"参数1"</span>, <span class="token string">"参数2"</span>]# exec格式</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p><code>COPY</code>:复制文件。从源路径复制到目标路径，源路径可以是多个，也可以是通配符。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">COPY</span> package.json /usr/src/app/</span><span class="token instruction"><span class="token keyword">COPY</span> <span class="token options"><span class="token property">--chown</span><span class="token punctuation">=</span><span class="token string">10:11</span></span> files* /mydir/# 复制时可改变读写权限</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p><code>ADD</code>:更高级的复制文件。跟 <code>COPY</code>的格式和性质基本一致，但是在 <code>COPY</code> 基础上增加了一些功能。使用时所有的文件复制均使用 <code>COPY</code>指令，仅在需要自动解压缩的场合使用 <code>ADD</code>。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">ADD</span> ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><code>CMD</code>:容器启动命令。Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。<code>CMD</code>指令就是用于指定默认的容器主进程的启动命令的。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">CMD</span> echo <span class="token variable">$HOME</span># shell格式，语法为：CMD &lt;命令></span><span class="token instruction"><span class="token keyword">CMD</span> [<span class="token string">"可执行文件"</span>, <span class="token string">"参数1"</span>, <span class="token string">"参数2"</span>...]# exec格式</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><blockquote><p>推荐使用 <code>exec</code> 格式，这类格式在解析时会被解析为 JSON数组，因此一定要使用双引号<code>"</code>，而不要使用单引号。使用<code>shell</code> 格式时，实际的命令会被包装为 <code>sh -c</code>的参数的形式进行执行，如上述命令会被拆解为CMD["sh", "-c", "echo$HOME"]。</p></blockquote><p><code>ENTRYPOINT</code>:入口点，格式也分为exec格式和shell格式，目的和<code>CMD</code> 一样，都是在指定容器启动程序及参数。这个命令目前还不是很明白。</p><p><code>ENV</code>:环境变量设置，格式有两种，示例如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">ENV</span> VERSION=1.0 DEBUG=on <span class="token operator">\</span>    NAME=<span class="token string">"Happy Feet"</span># ENV &lt;key1>=&lt;value1> &lt;key2>=&lt;value2>...</span><span class="token instruction"><span class="token keyword">ENV</span> NODE_VERSION 7.2.0# ENV &lt;key> &lt;value></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><code>ARG</code>:构建参数，和 <code>ENV</code>的效果一样，都是设置环境变量。所不同的是，<code>ARG</code>所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但注意不要用来保存密码，因为使用docker history能看到这些值。格式如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">ARG</span> DOCKER_USERNAME=library# ARG &lt;参数名>[=&lt;默认值>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><blockquote><p>ARG 指令有生效范围，如果在 <code>FROM</code>指令之前指定，那么只能用于 <code>FROM</code> 指令中。</p></blockquote><p><code>VOLUME</code>:定义匿名卷，格式为：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">VOLUME</span> [<span class="token string">"&lt;路径1>"</span>, <span class="token string">"&lt;路径2>"</span>...]</span><span class="token instruction"><span class="token keyword">VOLUME</span> &lt;路径></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p><code>EXPOSE</code>:暴露端口，声明容器运行时提供服务的端口，格式为：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">EXPOSE</span> &lt;端口1> [&lt;端口2>...]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><code>WORKDIR</code>:指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，<code>WORKDIR</code>会帮你建立目录。如果需要改变以后各层的工作目录的位置，那么 应该使用<code>WORKDIR</code> 指令。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">WORKDIR</span> /app# WORKDIR &lt;工作目录路径></span><span class="token instruction"><span class="token keyword">RUN</span> echo <span class="token string">"hello"</span> > world.txt</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><blockquote><p>如果你的 <code>WORKDIR</code>指令使用的相对路径，那么所切换的路径与之前的 <code>WORKDIR</code>有关。</p></blockquote><p><code>USER</code>:指定当前用户，<code>USER</code>只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">USER</span> redis# USER &lt;用户名>[:&lt;用户组>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><code>HEALTHCHECK</code>:健康检查,告诉 Docker应该如何进行判断容器的状态是否正常，格式如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">HEALTHCHECK</span> [选项] CMD &lt;命令># 设置检查容器健康状况的命令</span><span class="token instruction"><span class="token keyword">HEALTHCHECK</span> <span class="token keyword">NONE</span># 如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p><code>ONBUILD</code>:一个特殊的指令，它后面跟的是其它指令，比如<code>RUN</code>, <code>COPY</code> 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。</p><p><code>LABEL</code>:为镜像添加元数据，可以用一些标签来申明镜像的作者、文档地址等，格式如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">LABEL</span> &lt;key>=&lt;value> &lt;key>=&lt;value> &lt;key>=&lt;value> ...</span><span class="token instruction"><span class="token keyword">LABEL</span> maintainer=<span class="token string">"Erwan BERNARD https://github.com/edmBernard/DockerFiles"</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p><code>SHELL</code>: shell指令，可以指定<code>RUN</code><code>ENTRYPOINT</code> <code>CMD</code> 指令的 shell，Linux 中默认为["/bin/sh", "-c"]，格式如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">SHELL</span> [<span class="token string">"/bin/sh"</span>, <span class="token string">"-cex"</span>]# SHELL [<span class="token string">"executable"</span>, <span class="token string">"parameters"</span>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="docker构建">5.🎨Docker构建</h2><p>镜像的构建主要有以下几种方式：</p><h5 id="全部放到一个dockerfile中">全部放到一个DockerFile中</h5><p>​ 将项目及其依赖库的编译、测试、打包等流程都写到一个dockerfile中，这样可能会有些问题：</p><ul><li>镜像层次多，体积大，构建较慢；</li><li>源代码存在泄露的风险</li></ul><h5 id="分散到多个dockerfile">分散到多个DockerFile</h5><p>​ 事先在一个DockerFile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中，这种方式需要我们编写两个DockerFile和一些编译脚本才能将其两个阶段自动整合起来，这种方式虽然可以很好地规避第一种方式存在的风险，但明显部署过程较复杂。</p><h5 id="使用多阶段构建">使用多阶段构建</h5><p>​ 为解决以上问题，Docker v17.05 开始支持多阶段构建(<code>multistage builds</code>)。使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个DockerFile。</p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">FROM</span> golang:alpine <span class="token keyword">as</span> builder</span><span class="token instruction"><span class="token keyword">RUN</span> apk --no-cache add git</span><span class="token instruction"><span class="token keyword">WORKDIR</span> /go/src/github.com/go/helloworld/</span><span class="token instruction"><span class="token keyword">RUN</span> go get -d -v github.com/go-sql-driver/mysql</span><span class="token instruction"><span class="token keyword">COPY</span> app.go .</span><span class="token instruction"><span class="token keyword">RUN</span> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><span class="token instruction"><span class="token keyword">FROM</span> alpine:latest <span class="token keyword">as</span> prod</span><span class="token instruction"><span class="token keyword">RUN</span> apk --no-cache add ca-certificates</span><span class="token instruction"><span class="token keyword">WORKDIR</span> /root/</span><span class="token instruction"><span class="token keyword">COPY</span> <span class="token options"><span class="token property">--from</span><span class="token punctuation">=</span><span class="token string">0</span></span> /go/src/github.com/go/helloworld/app .</span><span class="token instruction"><span class="token keyword">CMD</span> [<span class="token string">"./app"</span>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>构建镜像</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> build -t go/helloworld:3 <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>若想只构建某一阶段的镜像，可以通过<code>as</code>来为某一阶段命名，构建时指定<code>--target</code>即可，如上面中<code>FROM golang:alpine as builder</code>，可通过如下命令来构建：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> build --target builder -t username/imagename:tag <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="编写dockerfile的一些良好习惯">6.💡编写DockerFile的一些良好习惯</h2><ul><li><p>通过DockerFile构建的镜像生命周期应该时短暂的，所需的配置应该尽可能小；</p></li><li><p>使用<code>.dockerignore</code>文件，DockerFile应该放在一个空文件夹下；</p></li><li><p>使用<strong>多阶段构建</strong>来减少所构建镜像的大小；</p></li><li><p>避免安装不必要的包；</p></li><li><p>一个容器中尽量只运行一个进程，多个应用应该解耦到不同容器中；</p></li><li><p>镜像层数尽可能少；</p></li><li><p>将多行参数按照字母顺序进行排序，建议在反斜杠符号<code>\</code>之前添加一个空格，以增加可读性，示例如下：</p><p><figure><div class="code-wrapper"><pre class="line-numbers language-docker" data-language="docker"><code class="language-docker"><span class="token instruction"><span class="token keyword">RUN</span> apt-get update &amp;&amp; apt-get install -y <span class="token operator">\</span>  bzr <span class="token operator">\</span>  cvs <span class="token operator">\</span>  git <span class="token operator">\</span>  mercurial <span class="token operator">\</span>  subversion</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure></p></li><li><p>在镜像的构建过程中，Docker 会遍历 <code>Dockerfile</code>文件中的指令，然后按顺序执行。在执行每条指令之前，Docker都会在缓存中查找是否已经存在可重用的镜像，如果有就使用现存的镜像，不再重复创建。如果你不想在构建过程中使用缓存，你可以在<code>docker build</code> 命令中使用 <code>--no-cache=true</code>选项。</p></li></ul><p>对于DockerFile中的一些指令，使用建议如下：</p><ul><li><code>FROM</code>：尽可能使用当前官方仓库作为你构建镜像的基础。推荐使用<a href="https://hub.docker.com/_/alpine/">Alpine</a> 镜像；</li><li><code>LABEL</code>：你可以给镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。每个标签一行，由<code>LABEL</code> 开头加上一个或多个标签对；</li><li><code>RUN</code>：建议将长的或复杂的 <code>RUN</code>指令用反斜杠<code>\</code>分割成多行，提高可读性和可维护性；</li><li><code>CMD</code>：<code>CMD</code> 大多数情况下都应该以<code>CMD ["executable", "param1", "param2"...]</code> 的形式使用；</li><li><code>ENV</code>：使用 <code>ENV</code> 来为容器中安装的程序更新<code>PATH</code> 环境变量，也可于设置常见的版本号；</li><li><code>ADD</code>和<code>COPY</code>：一般优先使用<code>COPY</code>；</li><li><code>VOLUME</code>：建议使用 <code>VOLUME</code>来管理镜像中的可变部分和用户可以改变的部分；</li><li><code>USER</code>：如果某个服务不需要特权执行，建议使用<code>USER</code> 指令切换到非 root 用户，避免使用<code>sudo</code>，避免频繁地使用 <code>USER</code> 来回切换用户；</li><li><code>WORKDIR</code>：建议总是在 <code>WORKDIR</code>中使用绝对路径。另外，你应该使用 <code>WORKDIR</code> 来替代类似于<code>RUN cd ... &amp;&amp; do-something</code>的指令，后者难以阅读、排错和维护。</li></ul><p><a href="https://github.com/docker-library/docs">这里</a>有很多官方镜像的DockerFile，可供学习参考。</p><h2 id="参考链接">7.参考链接</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://yeasy.gitbook.io/docker_practice/">Docker——从入门到实践</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>遥感领域预训练模型介绍</title>
    <link href="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/"/>
    <url>/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="遥感预训练模型介绍1">遥感预训练模型介绍<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="[GeoAI 2022第二期 | 基于遥感影像的预训练研究进展 ](https://www.bilibili.com/video/BV1y5411979L?spm_id_from=333.999.0.0)">[1]</span></a></sup></h1><p align="center"><a><img src="https://img.shields.io/badge/预训练模型-遥感-ff69b4"></a></p><h2 id="研究背景">研究背景</h2><p>​当前的遥感深度学习流程主要是通过一些在ImageNet上预训练过的模型(如CNN)来做下游的任务，包括遥感场景识别、遥感语义分割、遥感目标检测、遥感变化检测等任务。</p><p>​ 然而，自然图像和遥感卫星图像是存在较大差异的：</p><ul><li>从视角来看，遥感图像通常是俯视图，而自然图像则是前视视角居多；</li><li>从颜色来看，遥感影像的内容通常是一些城市、植被、山体等，颜色和自然影像相比比较单一；</li><li>从类别来看，遥感影像通常是室外自然环境、人工建筑、大型物体等，不像自然影像多种多样；</li><li>在物体的空间分布、尺度、遮挡等方面也存在各种各样的差异……</li></ul><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/图像差异.png" alt="图像差异"><figcaption aria-hidden="true">图像差异</figcaption></figure><p>​目前，遥感领域还缺乏像ImageNet这样的大规模有标签数据集，所以遥感预训练模型的相关工作较少出现，主要有：</p><ul><li><p>GeoKR：利用全球土地覆盖产品作为标签，使用mean-teacher框架来减轻RS图像与地理图像之间成像时间和分辨率差异的影响。然而，由于内在的不同数据分布，强制对齐不同的数据集不可避免地会带来错误。</p></li><li><p>SeCo:无监督预训练方法，利用季节变化来加强正样本之间的一致性，这是航空场景的独特特征，同时将时间信息和地理位置融合到MoCo-V2框架中，通过对比学习来进行训练。</p><p><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/GeoKR.png" alt="GeoKR" style="zoom:30%;"><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/SeCo.png" alt="SeCo" style="zoom:38%;"></p></li></ul><p>​上述的相关工作只考虑CNN的网络结构，对于目前的transformers结构还没有进行探索。鉴于此，论文提出了他的创新点：<strong>首次采用大规模场景标注的遥感数据集，对多种网络结构进行监督预训练，并在下游任务中进行综合性评估</strong>。</p><h2 id="实施方法">实施方法</h2><h3 id="数据millionaid2">数据：MillionAID<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Million-AID](https://captain-whu.github.io/DiRS/)">[2]</span></a></sup></h3><p>​遥感领域目前最大的开源数据集，包含100万个不重叠的场景，为RGB数据集(fMoW和BigEarthNet为多光谱数据集)，数据集一共包含八个baseclass，28个groups和51个leaves。最大、最小分辨率分别为0.5m和153m，图像大小分布在110* 110到31672 * 31762之间。</p><h3 id="模型vitaev2">模型：ViTAEv2</h3><p>​基于VIT模型的改进,具体文章和代码可参考<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="[ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for Image Recognition and Beyond](https://github.com/ViTAE-Transformer/ViTAE-Transformer)">[3]</span></a></sup>,模型结构图如下：</p><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/NetworkStructure.png" alt="NetworkStructure"><figcaption aria-hidden="true">NetworkStructure</figcaption></figure><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/ViTAEv2.png" alt="ViTAEv2"><figcaption aria-hidden="true">ViTAEv2</figcaption></figure><h3 id="训练">训练</h3><ol type="1"><li>从MillionAID中划分出一部分mini数据(训练集9775张影像，验证集225张影像)来进行预预训练，作者选取了ResNet-50、ViT、DeiT、PVT、Swin-T和ViTAE等网络架构，最终选定了ResNet-50、Swin-T和ViTAEv2-S作为代表模型；</li><li>将MillionAID划分训练集和验证集(验证集跟ImageNet验证集大小接近)，对ViTAEv2-S设置不同的epoch进行训练，根据验证集评估结果选择合适的epoch和相应权重(作者最终选取了epoch40和epoch100)，此外还选用了ResNet-50和Swin-T作为网络架构，进行相同的训练操作；</li></ol><h3 id="结果">结果</h3><center><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/ViTAEV2-S在不同epoch下的评估结果.png" alt="ViTAEV2-S在不同epoch下的评估结果"><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/不同模型评估结果对比.png" alt="不同模型评估结果对比"></figure></center><p>​上图为ViTAEv2-S模型在不同epoch下的效果，可以看出训练到40个epoch再往上后模型增速效果较为缓慢。下图为不同模型在不同epoch下的效果，训练40个epoch的ViTAEv2-S效果已经超过了训练300个epoch的Swin-T。</p><h2 id="下游应用">下游应用</h2><h3 id="场景识别">场景识别</h3><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/场景识别结果.png" alt="场景识别结果"><figcaption aria-hidden="true">场景识别结果</figcaption></figure><p>上图为论文中贴出来的来场景识别这个任务下的结果，可以看出：</p><ul><li>使用相同模型结构，通过ImageNet数据集和通过MillionAID数据集预训练出来的模型在场景识别任务上的表现，后者更佳；</li><li>通过遥感预训练的ViTAEv2-S模型，效果达到了SOTA。</li></ul><p>另外作者还对模型训练过程中的loss进行了分析，发现遥感预训练能加速模型收敛，并且最终loss更低。</p><h3 id="语义分割">语义分割</h3><p>​作者在Potsdam和iSAID数据集上进行实验，使用了UperNet框架，结果如下：</p><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/语义分割结果.png" alt="语义分割结果"><figcaption aria-hidden="true">语义分割结果</figcaption></figure><p>从语义分割实验结果可以看出：</p><ul><li>ViTAEv2-S在Potsdam数据集上总体精度最高，在iSAID数据集上mIOU为第一；</li><li>遥感预训练后，模型对于球场、桥梁等类别的识别精度有较大提升。</li></ul><h3 id="目标检测">目标检测</h3><p>​作者在DOTA数据集和HRSC2016数据集上进行实验，采用ORCN框架，结果如下：</p><center><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/目标检测_dota.png" alt="目标检测DOTA结果"><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/目标检测_hrsc.PNG" alt="目标检测HRSC2016结果"></figure></center><p>可以看出：</p><ul><li>ViTAEv2-S模型在这两个数据集上均达到了SOTA；</li><li>使用相同模型结构，通过ImageNet数据集和通过MillionAID数据集预训练出来的模型在目标检测任务上的表现，后者更佳；</li><li>使用遥感预训练后，模型对桥梁、飞机的识别效果更好。</li></ul><h3 id="变化检测">变化检测</h3><p>​作者在CDD和LEVIR数据集上进行实验，采用最新的BIT框架，实验结果如下：</p><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/变化检测结果.png" alt="变化检测结果"><figcaption aria-hidden="true">变化检测结果</figcaption></figure><p>可以看出：</p><ul><li>使用ImageNet数据集预训练的ViTAEv2-S模型在这两个数据集上均达到了SOTA；</li><li>遥感预训练模型的效果在变化检测任务上不如ImageNet预训练的效果好。</li></ul><h2 id="总结展望">总结展望</h2><p>​ 最终作者对模型在所有任务上的表现进行了总结，得出结论如下：</p><figure><img src="/2022/06/29/%E9%81%A5%E6%84%9F%E9%A2%86%E5%9F%9F%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/模型效果总结.png" alt="模型效果总结"><figcaption aria-hidden="true">模型效果总结</figcaption></figure><ul><li>训练更多epoch的模型，在下游任务上的表现更好；</li><li>ViTAEv2-S的总体表现最好。</li></ul><p>结合论文的所有实验结果，可以看出ViTAEv2模型在所有遥感任务上均达到了SOTA，同时经过遥感预训练后，模型对于遥感相关的类别(飞机、桥梁)识别的更加准确。同时论文中也提到目前还存在一些局限性，主要表现在以下几点：</p><ul><li>MillionAID数据集中的类别较少，只有51类；</li><li>预训练使用的是有监督训练，没有实验无监督训练(如MAE)的效果；</li><li>仅实验了Small版本的ViTAEv2模型，对于large版ViTAEv2模型，效果也许还有提升；</li><li>近研究了层级结构的Transformer模型，未研究plain结果的Transformer模型。</li></ul><h2 id="参考链接">参考链接</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://www.bilibili.com/video/BV1y5411979L?spm_id_from=333.999.0.0">GeoAI2022第二期 | 基于遥感影像的预训练研究进展</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://captain-whu.github.io/DiRS/">Million-AID</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://github.com/ViTAE-Transformer/ViTAE-Transformer">ViTAEv2:Vision Transformer Advanced by Exploring Inductive Bias for ImageRecognition and Beyond</a><a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>论文地址：<a href="https://arxiv.org/abs/2204.02825">https://arxiv.org/abs/2204.02825</a><a href="#fnref:4" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>遥感</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CV</tag>
      
      <tag>预训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知识图谱笔记</title>
    <link href="/2022/06/27/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/06/27/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="知识图谱笔记">知识图谱笔记</h1><p align="center"><a><img src="https://img.shields.io/badge/Muttermal-知识图谱-ff69b4"></a></p><h2 id="知识图谱的定义与架构">1.知识图谱的定义与架构</h2><h3 id="定义">1.1 定义</h3><p>​一种典型的多边关系图，由<strong>节点</strong>（实体）和<strong>边</strong>（实体之间的关系）组成。知识图谱本质上是一种语义网络，用于揭示万物之间的关系。</p><p>​ 知识图谱的一种通用表示是三元组的形式：<span class="math inline">\(G=\left\{ Entity_{head}, Relation, Entity_{tail}\right\}\)</span>，其中head和tail分别表示头尾实体，Relation为实体之间的关系。</p><h3 id="架构">1.2 架构</h3><p>​知识图谱的体系架构主要分为三部分。第一部分是源数据的获取，即如何获取数据并转化成结构化数据；第二部分是知识的融合，即关联多数据源的知识，扩大知识范围；第三部分是知识的计算和应用，主要体现在下游任务中。</p><figure><img src="/2022/06/27/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%AC%94%E8%AE%B0/知识图谱体系结构.png" alt="知识图谱体系结构"><figcaption aria-hidden="true">知识图谱体系结构</figcaption></figure><h2 id="知识图谱的构建技术">2.知识图谱的构建技术</h2><p>​由知识图谱的架构可知，知识图谱的构建主要包括<strong>知识抽取、知识融合、知识推理</strong>三个步骤。</p><h3 id="知识抽取">2.1 知识抽取</h3><p>​这部分主要对应于NLP任务中的<strong>NER任务</strong>(命名实体识别)和<strong>RE任务</strong>(关系抽取)，对应的思路和模型可参考<a href="https://github.com/PaddlePaddle/PaddleNLP/blob/develop/model_zoo/uie/README.md">百度的UIE模型</a>。</p><p>​在如今的部分场景下，仅仅只是文字(实体)之间的关系已经较难满足需求，如电商平台上需要构建商品图片与商品文字之间的关系图谱，不同商品之间的关联关系图谱等。随着多模态技术的兴起，越来越多的研究开始注重于不同模态数据之间关系的抽取，最具有代表性的工作为<a href="https://arxiv.org/abs/2103.00020">OpenAI的CLIP</a>。</p><p>​ 具体的思路和代码请参见相关的论文，此处不做讨论。</p><h3 id="知识融合">2.2 知识融合</h3><p>​知识融合将来自不同数据源的异构化、多样化的知识在同一个框架下进行消歧、加工、整合等，以达到数据、信息等多个角度融合的目的。知识融合的核心在于映射的生成。目前，知识融合技术可以分为<strong>本体融合</strong>和<strong>数据融合</strong>2个方面。</p><h4 id="本体融合">2.2.1 本体融合</h4><p>​本体融合是指将不同数据结构下或不同描述下的相同物体融合成一个，主要思路是本体映射和本体集成。前者是在多个本体之间建立映射规则，后者则是将多个本体集成为一个统一的本体。</p><p>​本体集成方法通常较为复杂，需耗费大量人力。本体映射方法主要分为以下四种：</p><ol type="1"><li>基于NLP的方法，比较映射对象之间的相似度，如PORTER提出的Stemming算法，用于寻找词形的变化；</li><li>基于结构的方法，如Stanford大学开发的AnchorPROMPT本体工具集；</li><li>基于实例的方法；</li><li>综合方法，如QOM。</li></ol><h4 id="数据融合">2.2.2 数据融合</h4><p>​数据统合包括<strong>实体合并、实体对齐、实体属性融合</strong>等方面，实体对齐算法主要分为三类：</p><ol type="1"><li>成对实体对齐；</li><li>局部实体对齐；</li><li>全局实体对齐</li></ol><h3 id="知识推理">2.3 知识推理</h3><p>​知识推理根据已有的实体关系信息来推断新的事实结论，从而进一步丰富知识图谱，满足上游任务的需求。知识推理方法主要分为三类：基于逻辑规则的推理、基于分布式特征表示的推理和基于深度学习的推理。</p><h4 id="基于逻辑规则的推理">2.3.1 基于逻辑规则的推理</h4><p>​包括谓词逻辑推理、本体推理和随机推理，代表算法为<strong>本体寻路算法</strong>(OntologicalPathfinding，OP)和<strong>双层随机游走算法</strong>(TRWA)。</p><h4 id="基于分布式特征表示的推理">2.3.2 基于分布式特征表示的推理</h4><p>​包括基于翻译模型的知识推理、基于张量分解的知识推理和基于语义匹配模型的知识推理。</p><h5 id="基于翻译模型的知识推理">2.3.2.1 基于翻译模型的知识推理</h5><p>​ 代表模型由TransE、TransH、TransR、TransD等，具体对比如下：</p><table><thead><tr class="header"><th>模型</th><th>基本思路</th><th>优点</th><th>不足</th></tr></thead><tbody><tr class="odd"><td>TransE</td><td>使head向量跟relation向量的和尽可能靠近tail向量，靠近程度可以用L1或L2范数来衡量。</td><td>基于翻译模型最早的作品，思路自然。</td><td>无法处理一对多的关系。</td></tr><tr class="even"><td>TransH</td><td>将head向量和tail向量投影到超平面上得到<span class="math inline">\(h_{\bot}和t_{\bot}\)</span>,其余思路跟TransE相同，使<span class="math inline">\(h_{\bot}+r尽可能靠近t_{\bot}\)</span>。</td><td>在TransE的基础上解决一对多的问题，且不增加模型复杂度。</td><td>假设实体和关系向量都在同一向量空间中，实际中可能不是这样。</td></tr><tr class="odd"><td>TransR</td><td>在两个不同的空间，即<strong>实体空间</strong>和<strong>多个关系空间</strong>(关系特定的实体空间)中建模实体和关系，并在对应的关系空间中进行转换。对于每个三元组(h,r,t)，将实体空间中的实体通过矩阵Mr投影到r关系空间中，分别为hr和tr，然后有hr+ r ≈ tr</td><td>去掉了TransH中的一致性假设。</td><td>1.head和tail使用相同的转换矩阵将自己投射到超平面上，但是head和tail通常是一个不同的实体；2.这个投影与实体和关系有关，但投影矩阵仅由关系决定；3.模型过于复杂。难以应用。</td></tr><tr class="even"><td>TransD</td><td>用两个向量来表示每个实体和关系。第一个向量表示实体或关系的意义，另一个向量(称为投影向量)将用于构造映射矩阵，投射和训练与TransR相同。</td><td></td><td></td></tr></tbody></table><figure><img src="/2022/06/27/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%AC%94%E8%AE%B0/不同翻译模型比较.png" alt="Trans模型总结"><figcaption aria-hidden="true">Trans模型总结</figcaption></figure><h5 id="基于张量分解的知识推理">2.3.2.2 基于张量分解的知识推理</h5><p>​一般将知识图谱中的实体关系三元组通过张量分解方法进行表示学习，将分解得到的向量重构为张量，元素值高于一定阈值的作为候选推理结果。代表模型为<strong>TRESCAL模型</strong>和<strong>DistMult模型</strong>。</p><h5 id="基于语义模型匹配的知识推理">2.3.2.3基于语义模型匹配的知识推理</h5><p>​这种方式认为每个关系都反映了相应实体的某些语义关系，可以通过选择性的加权来对这些关系进行表示和区分，因此，其提出统一加权模型（UnifiedWeighted Model，UWM）和独立加权模型（Independent WeightedModel，IWM）关系推理算法，计算效率较高。</p><h4 id="基于深度学习的推理">2.3.3 基于深度学习的推理</h4>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识图谱</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CLIP模型介绍</title>
    <link href="/2022/06/27/CLIP%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/"/>
    <url>/2022/06/27/CLIP%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="clip模型介绍">CLIP模型介绍</h1><p align="center"><a><img src="https://img.shields.io/badge/Muttermal-CLIP-ff69b4"></a></p><h2 id="模型介绍">1.模型介绍</h2><h3 id="动机">1.1 动机</h3><h3 id="模型思路">1.2 模型思路</h3><h3 id="实验效果">1.3 实验效果</h3><h2 id="代码实现">2.代码实现</h2><h2 id="其他相关工作">3.其他相关工作</h2><h2 id="后续工作进展">4.后续工作进展</h2><p>DALLE2</p><h2 id="参考资料">5.参考资料</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>多模态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对抗训练简介</title>
    <link href="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/"/>
    <url>/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="对抗训练简介">对抗训练简介</h1><p align="center"><a><img src="https://img.shields.io/badge/Muttermal-对抗训练-ff69b4"></a></p><h2 id="发展背景">1.发展背景</h2><p>​ 对抗训练（Adversarial Training）最初由 GAN之父IanGoodfellow等人提出<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)">[1]</span></a></sup>，作为一种防御对抗攻击的方法，最早应用在计算机视觉领域，用来解决利用对抗样本来恶意攻击模型的问题。</p><h2 id="基本思路">2.基本思路</h2><p>​ 我们定义<span class="math inline">\(D\)</span>为训练集，<span class="math inline">\(x\)</span>代表输入，<span class="math inline">\(y\)</span>代表标签，<span class="math inline">\(\theta\)</span>代表模型参数，<span class="math inline">\(L\)</span>为损失函数，<span class="math inline">\(r_{adv}\)</span>为扰动。对抗训练的思路就是在原始输入样本<span class="math inline">\(x\)</span>上增加一个扰动 <span class="math inline">\(r_{adv}\)</span>，得到<strong>对抗样本</strong>后，用其进行训练。我们可以把问题抽象成如下模型：<span class="math display">\[\min \limits_{\theta} -\log P(y|x+r_{adv};\theta)\]</span> 从模型优化的角度，我们可以将对抗训练拆解为两部分：</p><p>(1).从扰动的范围空间<span class="math inline">\(S\)</span>内找到对模型最有效的扰动，这部分可看作是对模型的攻击：<span class="math display">\[\max \limits_{r_{adv}\in S}L(\theta, x+r_{adv}, y)\]</span> (2).找到最鲁棒的模型参数<span class="math inline">\(\theta\)</span>使得对抗样本对模型的影响降到最低，也即模型的防御：<span class="math display">\[\min\limits_{\theta}E_{(x,y)\sim D}[\max\limits_{r_{adv}\in S}L(\theta,x+r_{adv}, y)]\]</span>上式就是对抗训练中最有名的Min-Max公式，它可以看成内部损失函数最大化+外部经验风险最小化的结合。</p><p>有了上述的分析，接下来的问题就在于：如何构造足够强的对抗样本？如何让模型具备最高的防御能力？</p><h3 id="对抗样本">对抗样本</h3><p>​ 在原论文中，作者提出了<strong>Fast Gradient SignMethod(FGSM)</strong>来构造输入样本的扰动。扰动的定义如下： <span class="math display">\[r_{adv} = \epsilon * sgn(\nabla_{x}L(\theta,x,y))\]</span> 其中<span class="math inline">\(sgn\)</span>为符号函数。</p><figure><img src="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/adv_sample.png" alt="熊猫加扰动后变成了长臂猿"><figcaption aria-hidden="true">熊猫加扰动后变成了长臂猿</figcaption></figure><p>​</p><p>从FGSM的设计中我们也可以总结出对抗样本需要具备的两个特点：</p><p>​ 1.添加的扰动需要是微小的，对抗样本与原始样本之间需要满足约束<span class="math inline">\(\left\| x^* - x \right\|_{\infty} =\left\|r_{adv}\right\|_{\infty}\leq \epsilon\)</span>；</p><p>​ 2.应该从Loss梯度上升的方向来添加扰动，从而尽量使模型出错。</p><h2 id="主要方法">3.主要方法</h2><p>​上述提到的思路都是基于CV领域提出的，CV的输入是连续的RGB的值，根据上述方法算出扰动后可以直接加到输入上来构造对抗样本。对于NLP领域来说，有没有办法将这种思路迁移过来呢？答案肯定是有的。NLP的输入一般为one-hot向量，直接在上面加扰动肯定是不行的，Goodfellow在文章<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)">[2]</span></a></sup>中提出可以在连续的embedding上做扰动。这种方法相较于CV来说最大的不同是，CV的对抗样本可以还原成图像，但是NLP的对抗样本无法还原成某个单词或词组。<strong>所以在NLP任务中，对抗训练的目的不再是为了防御基于梯度的恶意攻击，更多是作为一种正则化手段来提高模型的泛化能力。</strong></p><p>NLP中常见的对抗训练有以下几种：</p><h3 id="fast-gradient-methodfgm">3.1 <a href="https://arxiv.org/pdf/1605.07725.pdf">Fast GradientMethod(FGM)</a></h3><p>​FGM在上文提到的FGSM上做了一点改动，将原本的符号函数变成了映射到单位球面上的向量：<span class="math display">\[g = \nabla_{x}L(\theta,x,y), \quad r_{adv} = \epsilon * g / \left\| g\right\|_2\]</span> 上式中<span class="math inline">\(x\)</span>为embedding向量，主要代码如下<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="代码参考自：[【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现](https://zhuanlan.zhihu.com/p/91269728)">[4]</span></a></sup>：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""对于每个x:  1.计算x的前向loss、反向传播得到梯度  2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r  3.计算x+r的前向loss，反向传播得到对抗的梯度，累加到(1)的梯度上  4.将embedding恢复为(1)时的值  5.根据(3)的梯度对参数进行更新"""</span><span class="token keyword">class</span> <span class="token class-name">FGM</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model        self<span class="token punctuation">.</span>backup <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">def</span> <span class="token function">attack</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">,</span> emb_name<span class="token operator">=</span><span class="token string">'emb.'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 增加扰动</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad <span class="token keyword">and</span> emb_name <span class="token keyword">in</span> name<span class="token punctuation">:</span>                self<span class="token punctuation">.</span>backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>                norm <span class="token operator">=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>                <span class="token keyword">if</span> norm <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>                   <span class="token comment"># 一个batch内的样本统一用一个范数归一化</span>                    r_at <span class="token operator">=</span> epsilon <span class="token operator">*</span> param<span class="token punctuation">.</span>grad <span class="token operator">/</span> norm                    param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>r_at<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">restore</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_name<span class="token operator">=</span><span class="token string">'emb.'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 还原embedding向量</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad <span class="token keyword">and</span> emb_name <span class="token keyword">in</span> name<span class="token punctuation">:</span>                 <span class="token keyword">assert</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>backup                param<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span>        self<span class="token punctuation">.</span>backup <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>原论文的代码中，是对一个batch内的每个样本分别求范数。</p><h3 id="projected-gradient-descentpgd">3.2 <a href="https://arxiv.org/pdf/1706.06083.pdf">Projected GradientDescent(PGD)</a></h3><p>​<strong>PGD</strong>从<strong>FGM</strong>的一步到位改成了做多次迭代，在寻找最优扰动时，作者采用了<strong>”小步走，多走几步“</strong>的迭代方法，每次走一小步，每次迭代都将扰动映射到约束空间内：<span class="math display">\[x_{t+1} = \mathop{\Pi} \limits_{r_{adv}\in S}(x_t + r_{adv})\]</span></p><p><span class="math display">\[r_{adv}=\alpha*g(x_t)/ \left\| g(x_t)\right\|_2,\quad g =\nabla_{x}L(\theta,x,y)\]</span></p><p>其中<span class="math inline">\(S=\left\{ r\in R^d: \left\|r\right\|_2 \leq \epsilon \right\}\)</span>为扰动的约束空间，<span class="math inline">\(\alpha\)</span>为每一步的步长，<span class="math inline">\(\mathop{\Pi} \limits_{r_{adv}\in S}(x_t +r_{adv})\)</span>表示将<span class="math inline">\((x_t +r_{adv})\)</span>映射到<span class="math inline">\(S\)</span>上。主要代码如下<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="代码参考自：[【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现](https://zhuanlan.zhihu.com/p/91269728)">[4]</span></a></sup>：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""对于每个x:  1.计算x的前向loss、反向传播得到梯度并备份  对于每步t:    2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r(超出范围则投影回S内)    3.t不是最后一步: 将梯度归0，根据1的x+r计算前后向并得到梯度    4.t是最后一步: 恢复(1)的梯度，计算最后的x+r并将梯度累加到(1)上  5.将embedding恢复为(1)时的值  6.根据(4)的梯度对参数进行更新"""</span><span class="token keyword">class</span> <span class="token class-name">PGD</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model        self<span class="token punctuation">.</span>steps <span class="token operator">=</span> steps<span class="token comment"># 迭代步数</span>        self<span class="token punctuation">.</span>emb_backup <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>        self<span class="token punctuation">.</span>grad_backup <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token keyword">def</span> <span class="token function">attack</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1.</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> emb_name<span class="token operator">=</span><span class="token string">'emb.'</span><span class="token punctuation">,</span> is_first_attack<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># emb_name为模型中embedding的参数名</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad <span class="token keyword">and</span> emb_name <span class="token keyword">in</span> name<span class="token punctuation">:</span>                <span class="token keyword">if</span> is_first_attack<span class="token punctuation">:</span>                    self<span class="token punctuation">.</span>emb_backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>                norm <span class="token operator">=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>param<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>                <span class="token keyword">if</span> norm <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>                    r_at <span class="token operator">=</span> alpha <span class="token operator">*</span> param<span class="token punctuation">.</span>grad <span class="token operator">/</span> norm                    param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>r_at<span class="token punctuation">)</span>                    param<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>project<span class="token punctuation">(</span>name<span class="token punctuation">,</span> param<span class="token punctuation">.</span>data<span class="token punctuation">,</span> epsilon<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">restore</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> emb_name<span class="token operator">=</span><span class="token string">'emb.'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad <span class="token keyword">and</span> emb_name <span class="token keyword">in</span> name<span class="token punctuation">:</span>                 <span class="token keyword">assert</span> name <span class="token keyword">in</span> self<span class="token punctuation">.</span>emb_backup                param<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>emb_backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span>        self<span class="token punctuation">.</span>emb_backup <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>            <span class="token keyword">def</span> <span class="token function">project</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> param_name<span class="token punctuation">,</span> param_data<span class="token punctuation">,</span> epsilon<span class="token punctuation">)</span><span class="token punctuation">:</span>        r <span class="token operator">=</span> param_data <span class="token operator">-</span> self<span class="token punctuation">.</span>emb_backup<span class="token punctuation">[</span>param_name<span class="token punctuation">]</span>        <span class="token comment"># 如果扰动超出约束空间，就映射回去</span>        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>r<span class="token punctuation">)</span> <span class="token operator">></span> epsilon<span class="token punctuation">:</span>            r <span class="token operator">=</span> epsilon <span class="token operator">*</span> r <span class="token operator">/</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>r<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>emb_backup<span class="token punctuation">[</span>param_name<span class="token punctuation">]</span> <span class="token operator">+</span> r            <span class="token keyword">def</span> <span class="token function">backup_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>                self<span class="token punctuation">.</span>grad_backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">restore_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>                param<span class="token punctuation">.</span>grad <span class="token operator">=</span> self<span class="token punctuation">.</span>grad_backup<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>调用方式：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">pgd <span class="token operator">=</span> PGD<span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token keyword">for</span> batch_input<span class="token punctuation">,</span> batch_label <span class="token keyword">in</span> data<span class="token punctuation">:</span>    <span class="token comment"># 正常训练</span>    loss <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_input<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 反向传播，得到正常的grad</span>    pgd<span class="token punctuation">.</span>backup_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 对抗训练</span>    <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pgd<span class="token punctuation">.</span>steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        pgd<span class="token punctuation">.</span>attack<span class="token punctuation">(</span>is_first_attack<span class="token operator">=</span><span class="token punctuation">(</span>t<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># first attack时备份param.data</span>        <span class="token keyword">if</span> t <span class="token operator">!=</span> pgd<span class="token punctuation">.</span>steps <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>            model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            pgd<span class="token punctuation">.</span>restore_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_adv <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_input<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span>        loss_adv<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 反向传播，并在正常的grad基础上，累加对抗训练的梯度</span>    pgd<span class="token punctuation">.</span>restore<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 恢复embedding参数</span>    <span class="token comment"># 梯度下降，更新参数</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h3 id="free-adversarial-trainingfreeat5">3.3 <a href="https://arxiv.org/pdf/1904.12843.pdf">Free AdversarialTraining(FreeAT)</a><sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="[论文阅读：对抗训练(adversarial training)](https://zhuanlan.zhihu.com/p/104040055)">[5]</span></a></sup></h3><p>​ 从<strong>FGM</strong>到<strong>PGD</strong>，主要优化了扰动 <span class="math inline">\(r_{adv}\)</span>的计算，但是计算量也增加了。在<strong>FGM</strong>中，每个样本每次迭代需要计算两次（一次<span class="math inline">\(x\)</span>，一次<span class="math inline">\(x+r_{adv}\)</span>）,而<strong>PGD</strong>中则要计算<span class="math inline">\(K+1\)</span>次，消耗了更多的计算资源，而且在梯度下降时只利用了参数的梯度，梯度提升时只利用输入的梯度，有没有办法把计算出来的梯度和输入的梯度同时利用上呢？这就是<strong>FreeAT</strong>的核心思想。</p><p><strong>PGD</strong>采用的是对每个样本求K次梯度，K步走完后，才重新计算一次梯度用来更新模型参数，而<strong>FreeAT</strong>则是每走一步求一次梯度，更新一次模型参数，具体差别可以用下图来表示：</p><figure><img src="/2022/06/23/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83%E7%AE%80%E4%BB%8B/FreeAT.png" alt="FreeAT"><figcaption aria-hidden="true">FreeAT</figcaption></figure><p>​这样一来，<strong>FreeAT</strong>中模型参数更新的次数是普通训练的K倍，所以他把总体的epoch次数除以K来保证梯度计算次数跟普通训练的一样。这样会带来一个问题，一个mini-batch的样本被模型训练了K遍，可能影响到模型收敛的效果（论文中作者用实验结果表示这种担心不太必要）。</p><p>实现上，<strong>FreeAT</strong>在计算下一步扰动的梯度时，复用上一步的梯度，r的更新公式为：<span class="math display">\[r_{t+1} = r_t + \epsilon * sign(g),\quad g = \nabla_{x}L(\theta,x,y)\]</span></p><p>主要思路如下：</p><blockquote><p>初始化r=0 对于epoch=1...N/m: 对于每个x: 对于每步m:1.利用上一步的r，计算x+r的前后向loss，得到梯度 2.根据梯度更新参数3.根据梯度更新r</p></blockquote><h3 id="free-large-batchfreelb">3.4 <a href="https://arxiv.org/pdf/1909.11764.pdf">FreeLarge-Batch(FreeLB)</a></h3><p>​ 可以看到在<strong>PGD</strong>中只使用了最后一步<span class="math inline">\(x+r_{adv}\)</span>输出的梯度，<strong>FreeLB</strong>在这里做了改进，它取了每次迭代更新<span class="math inline">\(r_{adv}\)</span>过程中梯度的平均值，相当于在最大化扰动过程中，把原本的<span class="math inline">\(\max \limits_{r_{adv}\in S}L(\theta,x+r_{adv}, y)\)</span> 变成了 <span class="math inline">\(\frac{1}{K}\sum\limits_{t=0}^{K-1}\max\limits_{r_{t}\in S}L(\theta, x+r_{t}, y)\)</span>，其中 <span class="math inline">\(K\)</span> 为迭代的步数。</p><p>代码思路如下：</p><blockquote><p>对于每个x: 1.通过均匀分布初始化r，梯度g为0 对于每步t=1...K:2.根据x+r计算前后向，累计梯度g 3.更新r 4.根据g/K更新梯度</p></blockquote><p>论文中作者还指出<strong>对抗训练和dropout不能同时使用</strong>，dropout相当于改变了网络结构，会影响扰动<span class="math inline">\(r_{adv}\)</span> 的计算。</p><h3 id="smoothness-inducing-adversarial-reregularizationsmart">3.5 <a href="https://arxiv.org/pdf/1911.03437.pdf">SMoothness-inducingAdversarial ReRegularization(SMART)</a></h3><p>​前面提到的对抗训练方法都是针对添加扰动后传回的梯度进行处理，并没有在损失函数上做改动，而<strong>SMART</strong>则是在Loss上添加了一个正则项：<strong>Smoothness-inducingAdversarialRegularization</strong>，目的是在一定的范围内，找到对模型影响最大的扰动<span class="math inline">\(r\)</span>： <span class="math display">\[\mathcal{R}_s(\theta)=\frac{1}{n}\sum\limits_{i=1}^n \max\limits_{r_{i}\in S}l_s(f(x_i+r_{i};\theta), f(x_i;\theta))\]</span> 其中<span class="math inline">\(l_s\)</span>为<strong>对称的KL散度</strong><sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="对称KL散度又称JS散度，$JSD(P||Q) = \frac{1}{2}KL(P||M) + \frac{1}{2}KL(Q||M),\quad M=\frac{1}{2}(p+Q)$​，这里与传统的JS散度略有不同.">[3]</span></a></sup></p><p><span class="math display">\[l_s(P,Q) = D_{KL}(P||Q) + D_{KL}(Q||P)\]</span></p><p>模型的优化目标就在于 <span class="math display">\[\mathop{argmin}_\limits \theta \mathcal{F}(\theta) =\mathop{argmin}_\limits \theta \bigg(\mathcal{L}(\theta) +\lambda_s\mathcal{R}_s(\theta)\bigg)\]</span></p><p>为了求解（11）式，作者还提出了<strong>Bregman Proximal PointOptimization</strong>优化方法，对于第<span class="math inline">\(t+1\)</span>轮迭代： <span class="math display">\[\theta_{t+1} = \mathop{argmin}\limits_{\theta}\bigg(\mathcal{F}(\theta)+ \mu\mathcal{D}_{Breg}(\theta,\theta_t)\bigg)\]</span> 其中<span class="math inline">\(\theta_0\)</span>为预训练模型的参数，<span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>（布雷格曼散度）的定义如下：<span class="math display">\[\mathcal{D}_{Breg}(\theta,\theta_t)=\frac{1}{n}\sum\limits_{i=1}^nl_s(f(x_i;\theta), f(x_i;\theta_t))\]</span> <span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>也可以看做是一个正则项，用来防止模型参数更新的幅度过大。</p><p>在这两项正则项下，模型的最终损失函数可以写成如下形式： <span class="math display">\[\mathcal{F}(\theta) = \mathcal{L}(\theta) +\lambda_s\mathcal{R}_s(\theta) +\mu\mathcal{D}_{Breg}(\theta,\theta_t)\]</span> 最终的优化策略如下：</p><blockquote><p>对于第t轮迭代：</p><p>1.备份模型参数<span class="math inline">\(\theta\)</span>，作为计算<span class="math inline">\(\mathcal{D}_{Breg}(\theta,\theta_t)\)</span>中的<span class="math inline">\(\theta_t\)</span>；</p><p>2.对于每个batch内的第 <span class="math inline">\(i\)</span>个数据：</p><p>​ 使用正态分布随机初始化扰动<span class="math inline">\(r_i\)</span>，结合<span class="math inline">\(x_i\)</span>得到对抗样本 <span class="math inline">\(x_i+r_i\)</span>；</p><p>​ 对于m个小步：</p><p>​ 计算扰动下的梯度<span class="math inline">\(\widetildeg\)</span>；</p><p>​ 基于<span class="math inline">\(\widetildeg\)</span>和学习率更新对抗样本<span class="math inline">\(x_i+r_i\)</span>；</p><p>​ 基于对抗样本<span class="math inline">\(x_i+r_i\)</span>重新计算梯度，更新模型参数<span class="math inline">\(\theta\)</span>；</p><p>3.更新<span class="math inline">\(\theta_t,\quad\theta_t=(1-\beta)\theta + \beta\theta_t\)</span>，<span class="math inline">\(\beta\)</span>为动量参数。</p></blockquote><p>总体来说<strong>SMART</strong>的思路主要分为两部分：</p><p>1.训练过程中加入对embedding的随机扰动，要求模型的输出尽可能与扰动前的概率保持一致；</p><p>2.在模型更新参数时，修改优化器（Adam）的结果，要求模型参数与预训练时的参数分布相近，尽可能少改变。</p><h2 id="参考资料">参考资料</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://arxiv.org/abs/1412.6572">Explainingand Harnessing Adversarial Examples</a><a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://arxiv.org/abs/1605.07725">AdversarialTraining Methods for Semi-Supervised Text Classification</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>对称KL散度又称JS散度，<span class="math inline">(JSD(P||Q) = KL(P||M) + KL(Q||M),M=(p+Q))</span>​，这里与传统的JS散度略有不同.<a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>代码参考自：<a href="https://zhuanlan.zhihu.com/p/91269728">【炼丹技巧】功守道：NLP中的对抗训练+ PyTorch实现</a><a href="#fnref:4" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/104040055">论文阅读：对抗训练(adversarialtraining)</a><a href="#fnref:5" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对抗训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对比学习总结</title>
    <link href="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <url>/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="对比学习总结1">对比学习总结<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="本文CV部分总结自李沐老师的[视频](https://www.bilibili.com/video/BV19S4y1M7hm?spm_id_from=333.999.0.0)和[github](https://github.com/mli/paper-reading#contrastive_learning)。">[1]</span></a></sup></h1><p align="center"><a><img src="https://img.shields.io/badge/Muttermal-对比学习-ff69b4"></a></p><h2 id="cv">1.CV</h2><h3 id="百花齐放">百花齐放</h3><h4 id="instdisc"><strong><a href="https://arxiv.org/pdf/1805.01978.pdf">InstDisc</a></strong></h4><p>提出了<strong>个体判别任务</strong>和<strong>memorybank</strong>（字典形式）。正样本为自己，负样本为所有其他图片，负样本的特征存放在memorybank中。loss使用的是NCE loss。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608103708444.png" alt="InstDisc"><figcaption aria-hidden="true">InstDisc</figcaption></figure><p>skills: 由于memory bank里的特征数量通常较大，<strong>ProximalRegularizatio</strong>对memorybank里的特征进行动量更新，节省时间和内存。</p><p><a href="https://arxiv.org/pdf/1904.03436.pdf">InvaSpread</a></p><p>基本的对比学习，相似的物体特征应该保持不变性，不相似的物体特征应该尽量分散开。选取了<strong>个体判别任务</strong>。正样本为自己经过数据增强后的图片，负样本为batchsize里其他图片（包括原始图片和其数据增强后的图片），这样的好处在于，可以只用一个编码器去做端到端的训练。使用的loss为NCEloss的变体。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608105200188.png" alt="InvaSpread"><figcaption aria-hidden="true">InvaSpread</figcaption></figure><h4 id="cpc"><a href="https://arxiv.org/pdf/1807.03748.pdf">CPC</a></h4><p>选取了预测型的任务来做对比学习，对于模型的预测结果(z_t+1)来说，正样本为未来时刻的输入（x_t+1)通过编码器的输出，负样本为任意输入通过编码器的输出。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608105544159.png" alt="CPC"><figcaption aria-hidden="true">CPC</figcaption></figure><h4 id="cmc"><a href="https://arxiv.org/pdf/1906.05849.pdf">CMC</a></h4><p>多视角的对比学习，目的是增大所有视角之间的互信息，对于某个物体来说，正样本为其在其他视角（模态）下的信息，负样本为其他与物体</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608110638390.png" alt="CMC"><figcaption aria-hidden="true">CMC</figcaption></figure><h3 id="cv双雄">CV双雄</h3><h4 id="mocov1"><a href="https://arxiv.org/pdf/1911.05722.pdf">MoCov1</a></h4><p>把之前对比学习的方法都归纳成一个字典查询的问题，思路和<strong><a href="https://arxiv.org/pdf/1805.01978.pdf">InstDisc</a></strong>很类似。文章中提出了两个东西：<strong>队列</strong>和<strong>动量编码器</strong>，队列用来存储负样本的特征，动量编码器用来动态更新encoder，而不是动量的去更新负样本的特征。loss用的是infoNCE loss。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608111328200.png" alt="MoCov1"><figcaption aria-hidden="true">MoCov1</figcaption></figure><p>创新点：<strong>动量编码器</strong>，后续对比学习的工作还在沿用这个skill。</p><h4 id="simclrv1"><a href="https://arxiv.org/pdf/2002.05709.pdf">SimCLRv1</a></h4><p>正负样本的构造方式与<a href="https://arxiv.org/pdf/1904.03436.pdf">InvaSpread</a>相同，正样本为数据增强后的样本，负样本为batch里其他及其数据增强后的样本，simclr与InvaSpread的区别在于使用了更多的数据增强方式，在encoder后面增加了一个g函数(全连接层)，用了更大的batchsize（4096）。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608111947184.png" alt="SimCLRv1"><figcaption aria-hidden="true">SimCLRv1</figcaption></figure><p>创新点：在编码器后面加了一个mlp层（projector），效果有了很大的提升。</p><h4 id="mocov2"><a href="https://arxiv.org/pdf/2003.04297.pdf">MoCov2</a></h4><p>在原来的moco上面做了一些简单的改动，借鉴了simclr里面的一些技术，使用了更多的数据增强方式，以及在编码器后面加了一个mlp层，同时模型的训练epoch数也增加了（由200增加到800）。通常来说，无监督模型或者大型模型，训练越久模型效果越好。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608113045353.png" alt="MoCov2"><figcaption aria-hidden="true">MoCov2</figcaption></figure><h4 id="simclrv2"><a href="https://arxiv.org/pdf/2006.10029.pdf">SimCLRv2</a></h4><p>文章主要在讲大模型如何去做半监督学习。相比于simclrv1，论文的主要改动在于：换了一个更大的网络，实验了不同深度的mlp层(projectionhead)，使用了动量编码器。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608113611143.png" alt="SimCLRv2"><figcaption aria-hidden="true">SimCLRv2</figcaption></figure><p><a href="https://arxiv.org/pdf/2006.09882.pdf">SWaV</a></p><p>将对比学习和聚类的方法融合在了一起，将样本去跟负样本的聚类中心做对比。基本流程是样本x通过数据增强得到<span class="math inline">\(x_1, x_2\)</span>，再通过一个编码器<span class="math inline">\(f(\theta)\)</span>得到两个特征<span class="math inline">\(z_1,z_2\)</span>，接下来在与聚类中心c进行计算得到groundtruth <span class="math inline">\(Q_1,Q_2\)</span>，对<span class="math inline">\(Q_1, Q_2\)</span>进行训练。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608154756024.png" alt="SWaV"><figcaption aria-hidden="true">SWaV</figcaption></figure><p>skill: Multi-crop</p><h3 id="不用负样本">不用负样本</h3><h4 id="byol"><a href="https://arxiv.org/pdf/2006.07733.pdf">BYOL</a></h4><p>样本x通过两次不同的数据增强得到两个样本<span class="math inline">\(v,v&#39;\)</span>，再通过两个不同的编码器<span class="math inline">\(f(\theta)\)</span>（结构一样，参数不一样）得到两个特征<span class="math inline">\(y_{\theta},y&#39;_{\epsilon}\)</span>，然后再通过两个不同的mlp层得到<span class="math inline">\(z_{\theta}, z&#39;_{\epsilon}\)</span>，最终<span class="math inline">\(z_{\theta}\)</span>通过一个全连接层<span class="math inline">\(q_{\theta}\)</span>（网络结构与<span class="math inline">\(g_{\theta}\)</span>相同）得到<span class="math inline">\(q_{\theta}(z_{\theta})\)</span>，通过让<span class="math inline">\(q_{\theta}(z_{\theta})\)</span>去学习<span class="math inline">\(sg(z&#39;_{\epsilon})\)</span>来完成训练。其中下面的编码器和projector采用的是动量更新（类似于MoCo）。loss使用的是mseloss</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608160558770.png" alt="BYOL"><figcaption aria-hidden="true">BYOL</figcaption></figure><p>注：论文中使用的mlp层结构如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">def</span> <span class="token function">MLP</span><span class="token punctuation">(</span>dim<span class="token punctuation">,</span> projection_size<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> projection_size<span class="token punctuation">)</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>若去掉mlp层中的BatchNorm部分，模型效果会大大降低，原因在于去掉后会影像模型的初始化参数。</p><h4 id="simsiam"><a href="https://arxiv.org/pdf/2011.10566.pdf">SimSiam</a></h4><p>思路跟BYOL类似，样本x通过两次数据增强得到<span class="math inline">\(x_1,x_2\)</span>，x1通过编码器f和一个projector得到h，通过h去学习x2由编码器f解码出来的特征来完成训练，其中stop-grad至关重要。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608160528262.png" alt="SimSiam"><figcaption aria-hidden="true">SimSiam</figcaption></figure><p>simsiam与其他模型的对比如下：</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608164315837.png" alt="simsiam与其他模型的对比"><figcaption aria-hidden="true">simsiam与其他模型的对比</figcaption></figure><h3 id="transformer">Transformer</h3><h4 id="mocov3"><a href="https://arxiv.org/pdf/2104.02057.pdf">MoCov3</a></h4><p>模型网络结构融合了MoCo V2和SimSiam</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608165835942.png" alt="MoCov3"><figcaption aria-hidden="true">MoCov3</figcaption></figure><p>trick：MoCo V3将编码器由原来的resnet换成了VIT，且在训练时将VIT的patch projection层冻住（batchsize变大效果反而变差的问题在于patchprojection层在训练时梯度过大）。</p><p><a href="https://arxiv.org/pdf/2104.14294.pdf">DINO</a></p><p>思路和训练过程跟MoCo V3类似。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608170630626.png" alt="DINO"><figcaption aria-hidden="true">DINO</figcaption></figure><h4 id="clip"><a href="https://openai.com/blog/clip/">CLIP</a></h4><p>将文本信息和图片信息相结合。训练时，配对的图片和描述文本为正样本，不配对的图片和文本描述为负样本，然后利用对比学习来训练。预测时，通过prompt来构造文本描述，然后计算每个选项的置信度。论文的创新点在于：1.对于分类或检测任务，训练时不用再指定类别，只要在训练数据中出现过的类别，模型都可以通过prompt的形式来预测出来；2.打通了文本和图像的限制，文本编码器和图像编码器都可以使用transformer结构，为后续多模态模型的发展提供了统一框架的可能。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608170005523.png" alt="CLIP"><figcaption aria-hidden="true">CLIP</figcaption></figure><h2 id="nlp">2.NLP</h2><h4 id="simcse"><a href="https://arxiv.org/pdf/2104.08821.pdf">SimCSE</a></h4><p>​SimCSE论文中介绍了无监督和有监督两种训练方式。无监督训练时，作者将每个batch内的句子dropout两次，自己和自己为正样本，和batch内的其他句子为负样本，使用的loss为NSEloss： <span class="math display">\[\mathscr{l}_i = -\log \frac{e^{sim(h_i^{z_i}, h_i^{z_i&#39;})/\tau}}{\sum_{j=1}^N e^{sim(h_i^{z_i}, h_j^{z_j&#39;})/ \tau}}\]</span> 其中<span class="math inline">\(h_i^{z_i},h_i^{z_i&#39;}\)</span>为样本<span class="math inline">\(h_i\)</span>经过两次dropout后的结果。</p><p>​ 有监督训练时，对于样本对<span class="math inline">\((h_i, h_i^+,h_i^-)\)</span>，使用的loss如下： <span class="math display">\[-\log \frac{e^{sim(h_i, h_i^+)/ \tau}}{\sum_{j=1}^N \bigg( e^{sim(h_i,h_j^+)/ \tau} + e^{sim(h_i, h_j^-)/ \tau} \bigg)}\]</span> <img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/SimCSE.png" alt="SimCSE"></p><p>trick:作者使用dropout作为数据增强的方式，实现时每个batch内放两次同一个句子即可，又简单又有效果，可谓大道至简了。</p><p>​另外作者还提出了用<strong>Alignment（对齐性）</strong>和<strong>Uniformity（均匀性）</strong>来衡量一个模型的好坏，一个好的对比学习模型，应该是将相似的样本映射到尽可能聚拢的空间上，即具有对齐性；将不相似的样本映射到尽可能发散的空间上，即具有均匀性。</p><h4 id="esimcse2"><a href="https://arxiv.org/pdf/2109.04380.pdf">ESimCSE</a><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[ESimCSE：无监督语义新SOTA，引入动量对比学习扩展负样本，效果远超SimCSE](https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&amp;mid=2247488529&amp;idx=2&amp;sn=fc55d54811d985b7824782ffeff364fd&amp;scene=21#wechat_redirect)">[2]</span></a></sup></h4><p>​ESimCSE为SimCSE的增强版。SimCSE直接通过dropout两次来构造正样本，这样会导致正例对具有相同的长度，而负例对通常包含不同的长度信息，模型有可能会通过这一特征来区分正负样本。针对这一点，作者提出了<strong>WordRepetition</strong>的方法，即随机复制句子中的一些单词来使正例对的长度不同。另外作者还使用了动量编码器，动量编码器最早在MoCo中就有使用。</p><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/ESimCSE.png" alt="EsimCSE"><figcaption aria-hidden="true">EsimCSE</figcaption></figure><h4 id="consert3"><a href="https://arxiv.org/pdf/2105.11741.pdf">ConSERT</a><sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="[ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%](https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html)">[3]</span></a></sup></h4><p>​ 作者也是在SimCSE的基础上进行了改进，主要改进点如下：</p><ul><li>一个数据增强模块，作用于Embedding层，为同一个句子生成两个不同的增强版本（View）；</li><li>一个共享的BERT编码器，为输入的句子生成句向量。</li><li>一个对比损失层，用于在一个Batch的样本中计算对比损失，其思想是最大化同一个样本不同增强版本句向量的相似度，同时使得不同样本的句向量相互远离。</li></ul><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/ConSERT.png" alt="ConSERT"><figcaption aria-hidden="true">ConSERT</figcaption></figure><p>​作者探索了不同的数据增强方式，包括<strong>对抗攻击</strong>，<strong>打乱词序</strong>，<strong>裁剪</strong>，<strong>Dropout</strong>，其中裁剪包括TokenCutoff(随机选取Token，将对应Token的Embedding整行置为零)和FeatureCutoff(随机选取Embedding的Feature，将选取的Feature维度整列置为零)。作者的结果显示打乱词序和FeatureCutoff的组合取得了最优性能。此外，就单种数据增强方法而言，打乱词序 &gt;Token Cutoff &gt;&gt; Feature Cutoff ≈ Dropout &gt;&gt; None。</p><h2 id="总结">3.总结</h2><figure><img src="/2022/06/21/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20220608174138168.png" alt="对比学习总结"><figcaption aria-hidden="true">对比学习总结</figcaption></figure><h2 id="参考资料">参考资料</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>本文CV部分总结自李沐老师的<a href="https://www.bilibili.com/video/BV19S4y1M7hm?spm_id_from=333.999.0.0">视频</a>和<a href="https://github.com/mli/paper-reading#contrastive_learning">github</a>。<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&amp;mid=2247488529&amp;idx=2&amp;sn=fc55d54811d985b7824782ffeff364fd&amp;scene=21#wechat_redirect">ESimCSE：无监督语义新SOTA，引入动量对比学习扩展负样本，效果远超SimCSE</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://tech.meituan.com/2021/06/03/acl-2021-consert-bert.html">ACL2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%</a><a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对比学习</tag>
      
      <tag>CV</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/06/20/Hello/"/>
    <url>/2022/06/20/Hello/</url>
    
    <content type="html"><![CDATA[<h1 id="welcome-to-my-blog">Welcome to My Blog</h1><p align="center"><a><img src="https://img.shields.io/badge/Muttermal-Hello-ff69b4"></a></p><blockquote><p>Welcome to My Blog!</p></blockquote><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Welcome to My Blog!"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><figure><img src="/2022/06/20/Hello/hello.jpg" alt="Hello"><figcaption aria-hidden="true">Hello</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>其他</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
